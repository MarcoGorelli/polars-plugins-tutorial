{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"How you (yes, you!) can write a Polars Plugin","text":"<ul> <li>\u2705 Unlock super-high performance</li> <li>\u2705 Have a tonne of fun</li> <li>\u2705 Impress everybody with your superpowers</li> </ul>"},{"location":"#why","title":"Why?","text":"<p>Polars is an incredible and groundbreaking Dataframe library, and its expressions API is simply amazing. Sometimes, however, you need to express really custom business logic which just isn't in scope for the Polars API. In that situation, people tend to use <code>map_elements</code>, which lets you express anything but also kills most of Polars' benefits.</p> <p>But it doesn't have to be that way - with just basic Rust knowledge and this tutorial, I postulate that you'll be able to address at least 99% of inefficient <code>map_elements</code> tasks!</p>"},{"location":"#what-will-you-learn","title":"What will you learn","text":"<ul> <li>Writing simple single-column elementwise expressions</li> <li>Writing complex multi-column non-elementwise expressions which use third-party Rust packages</li> <li>How to share your plugin superpowers with others</li> </ul>"},{"location":"#what-are-people-saying","title":"What are people saying?","text":"<p>Nelson Griffiths, Engineering &amp; ML Lead at Double River Investments | Core Maintainer Functime</p> <p>this was an awesome intro. I am no rust expert, though I have written a few plugins. And I learned quite a bit from this! Having my team read it now as well. Thanks for putting this together. I think more content like this for people who don\u2019t know how to write optimal polars code on the rust side will be really useful for people like me who want to work on plugins!</p> <p>Barak David, Software Engineer</p> <p>Amazing tutorial! I just created nltk plugin, and experienced X50 speedup!</p>"},{"location":"abs/","title":"2. How to do ABSolutely nothing","text":"<p>OK, the title's misleading. We won't do \"nothing\", we'll make an <code>abs</code> function which will work on numeric data.</p> <p>We'll do this in phases:</p> <ul> <li><code>abs_i64</code> will take the absolute value of each row of an <code>Int64</code> column</li> <li><code>abs_numeric</code> will take the absolute value of each row in any numeric column</li> </ul>"},{"location":"abs/#abs_i64","title":"<code>abs_i64</code>","text":"<p>Let's start with the Python side - this is almost the same as what we did for <code>noop</code>, we'll just change the names. Please add this to <code>minimal_plugin/__init__.py</code>, right below the definition of <code>noop</code>: <pre><code>def abs_i64(expr: IntoExprColumn) -&gt; pl.Expr:\n    return register_plugin_function(\n        args=[expr],\n        plugin_path=LIB,\n        function_name=\"abs_i64\",\n        is_elementwise=True,\n    )\n</code></pre></p> <p>Then, please add this to <code>src/expressions.rs</code>, right below the Rust definition of <code>noop</code>:</p> <pre><code>#[polars_expr(output_type=Int64)]\nfn abs_i64(inputs: &amp;[Series]) -&gt; PolarsResult&lt;Series&gt; {\n    let s = &amp;inputs[0];\n    let ca: &amp;Int64Chunked = s.i64()?;\n    // NOTE: there's a faster way of implementing `abs_i64`, which we'll\n    // cover in section 7.\n    let out: Int64Chunked = ca.apply(|opt_v: Option&lt;i64&gt;| opt_v.map(|v: i64| v.abs()));\n    Ok(out.into_series())\n}\n</code></pre> <p>The general idea here is:</p> <ul> <li> <p>Each element <code>opt_v</code> can either be <code>Some(i64)</code>, or <code>None</code>.   If it's <code>None</code>, we return <code>None</code>, whereas if it's <code>Some(i64)</code>,   then we return <code>Some</code> of the absolute value of the <code>i64</code> value.</p> <p>Note</p> <p>There's a faster way of implementing <code>abs_i64</code>, which you'll learn about in Branch mispredictions.</p> </li> <li> <p>We produce a new ChunkedArray, convert it to Series, and return it.</p> </li> </ul> <p>Let's try this out. Make a Python file <code>run.py</code> with the following: <pre><code>import polars as pl\nimport minimal_plugin as mp\n\ndf = pl.DataFrame({\n    'a': [1, -1, None],\n    'b': [4.1, 5.2, -6.3],\n    'c': ['hello', 'everybody!', '!']\n})\nprint(df.with_columns(mp.abs_i64('a').name.suffix('_abs')))\n</code></pre> Compile it with <code>maturin develop</code> (or <code>maturin develop --release</code> if you're benchmarking), and run it with <code>python run.py</code>. If it outputs <pre><code>shape: (3, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a    \u2506 b    \u2506 c          \u2506 a_abs \u2502\n\u2502 ---  \u2506 ---  \u2506 ---        \u2506 ---   \u2502\n\u2502 i64  \u2506 f64  \u2506 str        \u2506 i64   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 4.1  \u2506 hello      \u2506 1     \u2502\n\u2502 -1   \u2506 5.2  \u2506 everybody! \u2506 1     \u2502\n\u2502 null \u2506 -6.3 \u2506 !          \u2506 null  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> then you did everything correctly!</p>"},{"location":"abs/#abs_numeric","title":"<code>abs_numeric</code>","text":"<p>The code above unfortunately only supports <code>Int64</code> columns. Let's try to generalise it a bit, so that it can accept any signed numeric column.</p> <p>First, add the following definition to <code>minimal_plugin/__init__.py</code>:</p> <pre><code>def abs_numeric(expr: IntoExprColumn) -&gt; pl.Expr:\n    return register_plugin_function(\n        args=[expr],\n        plugin_path=LIB,\n        function_name=\"abs_numeric\",\n        is_elementwise=True,\n    )\n</code></pre> <p>Then, we'll go back to <code>src/expressions.rs</code>. Paste in the following:</p> <pre><code>fn impl_abs_numeric(ca: &amp;Int64Chunked) -&gt; Int64Chunked {\n    // NOTE: there's a faster way of implementing `abs`, which we'll\n    // cover in section 7.\n    ca.apply(|opt_v: Option&lt;i64&gt;| opt_v.map(|v: i64| v.abs()))\n}\n\n#[polars_expr(output_type=Int64)]\nfn abs_numeric(inputs: &amp;[Series]) -&gt; PolarsResult&lt;Series&gt; {\n    let s = &amp;inputs[0];\n    let ca: &amp;Int64Chunked = s.i64()?;\n    let out = impl_abs_numeric(ca);\n    Ok(out.into_series())\n}\n</code></pre> <p>Note how it's exactly like <code>abs_i64</code>, but <code>impl_abs_numeric</code> was factored out of the <code>abs_numeric</code> function. It's not yet generic, we need to do a bit more work. The general idea is:</p> <ul> <li>each <code>ChunkedArray</code> is of some Polars Type <code>T</code> (e.g. <code>Int64</code>);</li> <li>to each Polars Type <code>T</code>, there corresponds a Rust native type <code>T::Native</code> (e.g. <code>i64</code>).</li> </ul> <p>Change <code>impl_abs_numeric</code> to:</p> <p><pre><code>fn impl_abs_numeric&lt;T&gt;(ca: &amp;ChunkedArray&lt;T&gt;) -&gt; ChunkedArray&lt;T&gt;\nwhere\n    T: PolarsNumericType,\n    T::Native: Signed,\n{\n    // NOTE: there's a faster way of implementing `abs`, which we'll\n    // cover in section 7.\n    ca.apply(|opt_v: Option&lt;T::Native&gt;| opt_v.map(|v: T::Native| v.abs()))\n}\n</code></pre> Make sure to add <pre><code>use pyo3_polars::export::polars_core::export::num::Signed;\n</code></pre> to the top of the <code>src/expression.rs</code> file.</p> <p>We then need to modify <code>abs_numeric</code> as follows: <pre><code>#[polars_expr(output_type_func=same_output_type)]\nfn abs_numeric(inputs: &amp;[Series]) -&gt; PolarsResult&lt;Series&gt; {\n    let s = &amp;inputs[0];\n    match s.dtype() {\n        DataType::Int32 =&gt; Ok(impl_abs_numeric(s.i32().unwrap()).into_series()),\n        DataType::Int64 =&gt; Ok(impl_abs_numeric(s.i64().unwrap()).into_series()),\n        DataType::Float32 =&gt; Ok(impl_abs_numeric(s.f32().unwrap()).into_series()),\n        DataType::Float64 =&gt; Ok(impl_abs_numeric(s.f64().unwrap()).into_series()),\n        dtype =&gt; {\n            polars_bail!(InvalidOperation:format!(\"dtype {dtype} not \\\n            supported for abs_numeric, expected Int32, Int64, Float32, Float64.\"))\n        }\n    }\n}\n</code></pre> That's it! Our function is now generic over signed numeric types, instead of only accepting the <code>Int64</code> type.</p> <p>Finally, modify the <code>print</code> line of <code>run.py</code> to be <pre><code>print(df.with_columns(mp.abs_numeric(pl.col('a', 'b')).name.suffix('_abs')))\n</code></pre></p> <p>Compile with <code>maturin develop</code> (or <code>maturin develop --release</code> if you're benchmarking) and then run with <code>python run.py</code>. You should see: <pre><code>shape: (3, 5)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a    \u2506 b    \u2506 c          \u2506 a_abs \u2506 b_abs \u2502\n\u2502 ---  \u2506 ---  \u2506 ---        \u2506 ---   \u2506 ---   \u2502\n\u2502 i64  \u2506 f64  \u2506 str        \u2506 i64   \u2506 f64   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 4.1  \u2506 hello      \u2506 1     \u2506 4.1   \u2502\n\u2502 -1   \u2506 5.2  \u2506 everybody! \u2506 1     \u2506 5.2   \u2502\n\u2502 null \u2506 -6.3 \u2506 !          \u2506 null  \u2506 6.3   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Note how we were able to take the absolute value of both <code>b</code> (<code>f64</code>) and <code>a</code> (<code>i64</code>) columns with <code>abs_numeric</code>!</p>"},{"location":"aggregate/","title":"15. In (the) aggregate","text":"<p>Enough transorming columns! Let's aggregate them instead.</p> <p>A Polars expression is a function from a Dataframe to a Series. So, how can we possibly write an expression which produces a scalar?</p> <p>Simple:</p> <ul> <li>write an expression which returns a 1-row Series</li> <li>when you register the expression, pass <code>returns_scalar = True</code></li> </ul> <p>As an example, let's compute the weighted mean of a column, where the weights are given by a second column.</p>"},{"location":"aggregate/#hello-python-my-old-friend","title":"Hello Python my old friend","text":"<p>Nothing fancy here:</p> <pre><code>def vertical_weighted_mean(values: IntoExprColumn, weights: IntoExprColumn) -&gt; pl.Expr:\n    return register_plugin_function(\n        args=[values, weights],\n        plugin_path=LIB,\n        function_name=\"vertical_weighted_mean\",\n        is_elementwise=False,\n        returns_scalar=True,\n    )\n</code></pre>"},{"location":"aggregate/#rust","title":"Rust","text":"<p>To keep this example's complexity down, let's just limit it to <code>Float64</code> columns.</p> <pre><code>#[polars_expr(output_type=Float64)]\nfn vertical_weighted_mean(inputs: &amp;[Series]) -&gt; PolarsResult&lt;Series&gt; {\n    let values = &amp;inputs[0].f64()?;\n    let weights = &amp;inputs[1].f64()?;\n    let mut numerator = 0.;\n    let mut denominator = 0.;\n    values.iter().zip(weights.iter()).for_each(|(v, w)| {\n        if let (Some(v), Some(w)) = (v, w) {\n            numerator += v * w;\n            denominator += w;\n        }\n    });\n    let result = numerator / denominator;\n    Ok(Series::new(PlSmallStr::EMPTY, vec![result]))\n}\n</code></pre>"},{"location":"aggregate/#run-it","title":"Run it!","text":"<p>Put the following in <code>run.py</code>:</p> <pre><code>df = pl.DataFrame({\n    'values': [1., 3, 2, 5, 7],\n    'weights': [.5, .3, .2, .1, .9],\n    'group': ['a', 'a', 'a', 'b', 'b'],\n})\nprint(df.group_by('group').agg(weighted_mean = mp.vertical_weighted_mean('values', 'weights')))\n</code></pre> <p>If you compile with <code>maturin develop</code> (or <code>maturin develop --release</code> if benchmarking), you'll see:</p> <pre><code>shape: (2, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 group \u2506 weighted_mean \u2502\n\u2502 ---   \u2506 ---           \u2502\n\u2502 str   \u2506 f64           \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 b     \u2506 6.166667      \u2502\n\u2502 a     \u2506 2.333333      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Try omitting <code>returns_scalar=True</code> when registering the expression - what changes?</p>"},{"location":"arguments/","title":"8. I'd like to have an argument, please","text":"<p>Say you want to rewrite <pre><code>def add_suffix(s, *, suffix):\n    return s + suffix\n\ns.map_elements(lambda x: add_suffix(x, suffix='-billy'))\n</code></pre> as a plugin. How can you do that?</p> <p>We've covered passing in extra columns, but...how about passing extra keyword arguments?</p> <p>We'll do this with <code>kwargs</code>. In <code>minimal_plugin/__init__.py</code>, add the following:</p> <pre><code>def add_suffix(expr: IntoExprColumn, *, suffix: str) -&gt; pl.Expr:\n    return register_plugin_function(\n        args=[expr],\n        plugin_path=LIB,\n        function_name=\"add_suffix\",\n        is_elementwise=True,\n        kwargs={\"suffix\": suffix},\n    )\n</code></pre> <p>In <code>src/expressions.rs</code>, we'll then first have to define a struct to hold our keyword-arguments:</p> <p><pre><code>#[derive(Deserialize)]\nstruct AddSuffixKwargs {\n    suffix: String,\n}\n</code></pre> Make sure to also add <pre><code>use serde::Deserialize;\n</code></pre> to the top of the file.</p> <p>Then, we can just pass an argument of this type to a <code>add_suffix</code> function, which is going to be very similar to the good version of <code>pig_latinnify</code>:</p> <pre><code>#[polars_expr(output_type=String)]\nfn add_suffix(inputs: &amp;[Series], kwargs: AddSuffixKwargs) -&gt; PolarsResult&lt;Series&gt; {\n    let s = &amp;inputs[0];\n    let ca = s.str()?;\n    let out = ca.apply_into_string_amortized(|value, output| {\n        write!(output, \"{}{}\", value, kwargs.suffix).unwrap();\n    });\n    Ok(out.into_series())\n}\n</code></pre> <p>To see it in action, compile with <code>maturin develop</code> (or <code>maturin develop --release</code> if you're benchmarking), and then you should be able to put <pre><code>import polars as pl\nimport minimal_plugin as mp\n\ndf = pl.DataFrame({'a': ['bob', 'billy']})\nprint(df.with_columns(mp.add_suffix('a', suffix='-billy')))\n</code></pre> into <code>run.py</code>, and run it to get <pre><code>shape: (2, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a           \u2502\n\u2502 ---         \u2502\n\u2502 str         \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 bob-billy   \u2502\n\u2502 billy-billy \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> You can add multiple keyword-arguments in the same function, just make sure to include them in the struct which you define on the Rust side.</p>"},{"location":"arrays/","title":"11. ARRAY, captain!","text":"<p>We've talked about lists, structs, but what about arrays?</p> <p>In this section we're gonna cover how to deal with fixed sized arrays, e.g., x and y coordinates of 2d points in the same column:</p> <pre><code>points = pl.Series(\n    \"points\",\n    [\n        [6.63, 8.35],\n        [7.19, 4.85],\n        [2.1, 4.21],\n        [3.4, 6.13],\n    ],\n    dtype=pl.Array(pl.Float64, 2),\n)\ndf = pl.DataFrame(points)\n\nprint(df)\n</code></pre> <pre><code>shape: (4, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 points        \u2502\n\u2502 ---           \u2502\n\u2502 array[f64, 2] \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 [6.63, 8.35]  \u2502\n\u2502 [7.19, 4.85]  \u2502\n\u2502 [2.1, 4.21]   \u2502\n\u2502 [3.4, 6.13]   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Let's get to work - what if we wanted to make a plugin that takes a Series like <code>points</code> above, and, likewise, returned a Series of arrays? Turns out we can do it! But it's a little bit tricky.</p> <p>First of all, we need to include <code>features = [\"dtype-array\"]</code> in both <code>pyo3-polars</code> and <code>polars-core</code> in our <code>Cargo.toml</code>.</p> <p>Now let's create a plugin that calculates the midpoint between a reference point and each point in a Series like the one above. This should illustrate both how to unpack an array inside our Rust code and also return a Series of the same type.</p> <p>We'll start by registering our plugin:</p> <pre><code>def midpoint_2d(expr: IntoExprColumn, ref_point: tuple[float, float]) -&gt; pl.Expr:\n    return register_plugin_function(\n        args=[expr],\n        plugin_path=Path(__file__).parent,\n        function_name=\"midpoint_2d\",\n        is_elementwise=True,\n        kwargs={\"ref_point\": ref_point},\n    )\n</code></pre> <p>As you can see, we included an additional kwarg: <code>ref_point</code>, which we annotated with the type <code>tuple: [float, float]</code>. In our Rust code, we won't receive it as a tuple, though, it'll also be an array. This isn't crucial for this example, so just accept it for now. As you saw in the arguments chapter, we take kwargs by defining a struct for them:</p> <pre><code>#[derive(Deserialize)]\nstruct MidPoint2DKwargs {\n    ref_point: [f64; 2],\n}\n</code></pre> <p>And we can finally move to the actual plugin code:</p> <pre><code>// We need this to ensure the output is of dtype array.\n// Unfortunately, polars plugins do not support something similar to:\n// #[polars_expr(output_type=Array)]\npub fn point_2d_output(_: &amp;[Field]) -&gt; PolarsResult&lt;Field&gt; {\n    Ok(Field::new(\n        PlSmallStr::from_static(\"point_2d\"),\n        DataType::Array(Box::new(DataType::Float64), 2),\n    ))\n}\n\n#[polars_expr(output_type_func=point_2d_output)]\nfn midpoint_2d(inputs: &amp;[Series], kwargs: MidPoint2DKwargs) -&gt; PolarsResult&lt;Series&gt; {\n    let ca: &amp;ArrayChunked = inputs[0].array()?;\n    let ref_point = kwargs.ref_point;\n\n    let out: ArrayChunked = unsafe {\n        ca.try_apply_amortized_same_type(|row| {\n            let s = row.as_ref();\n            let ca = s.f64()?;\n            let out_inner: Float64Chunked = ca\n                .iter()\n                .enumerate()\n                .map(|(idx, opt_val)| {\n                    opt_val.map(|val| {\n                        (val + ref_point[idx]) / 2.0f64\n                    })\n                }).collect_trusted();\n            Ok(out_inner.into_series())\n        })}?;\n\n    Ok(out.into_series())\n}\n</code></pre> <p>Uh-oh, unsafe, we're doomed!</p> <p>Hold on a moment - it's true that we need unsafe here, but let's not freak out. If we read the docs of <code>try_apply_amortized_same_type</code>, we see the following:</p> <pre><code>/// Try apply a closure `F` to each array.\n///\n/// # Safety\n/// Return series of `F` must has the same dtype and number of elements as input if it is Ok.\npub unsafe fn try_apply_amortized_same_type&lt;F&gt;(&amp;self, mut f: F) -&gt; PolarsResult&lt;Self&gt;\nwhere\n    F: FnMut(AmortSeries) -&gt; PolarsResult&lt;Series&gt;,\n</code></pre> <p>In this example, we can uphold that contract - we know we're returning a Series with the same number of elements and same dtype as the input!</p> <p>Still, the code looks a bit scary, doesn't it? So let's break it down:</p> <pre><code>let out: ArrayChunked = unsafe {\n\n    // This is similar to apply_values, but it's amortized and made specifically\n    // for arrays.\n    ca.try_apply_amortized_same_type(|row| {\n        let s = row.as_ref();\n        // `s` is a Series which contains two elements.\n        // We unpack it similarly to the way we've been unpacking Series in the\n        // previous chapters:\n        //\n        // Previously we've been doing this to unpack a column we had behind a\n        // Series - this time, inside this closure, the Series contains the two\n        // elements composing the \"row\" (x and y):\n        let ca = s.f64()?;\n\n        // There are many ways to extract the x and y coordinates from ca.\n        // Here, we remain idiomatic and consistent with what we've been doing\n        // in the past - iterate, enumerate and map:\n        let out_inner: Float64Chunked = ca\n            .iter()\n            .enumerate()\n            .map(|(idx, opt_val)| {\n\n                // We only use map here because opt_val is an Option\n                opt_val.map(|val| {\n\n                    // Here's where the simple logic of calculating a\n                    // midpoint happens. We take the coordinate (`val`) at\n                    // index `idx`, add it to the `idx-th` entry of our\n                    // reference point (which is a coordinate of our point),\n                    // then divide it by two, since we're dealing with 2d\n                    // points only.\n                    (val + ref_point[idx]) / 2.0f64\n                })\n                // Our map already returns Some or None, so we don't have to\n                // worry about wrapping the result in, e.g., Some()\n            }).collect_trusted();\n\n        // At last, we convert out_inner (which is a Float64Chunked) back to a\n        // Series\n        Ok(out_inner.into_series())\n    })}?;\n\n// And finally, we convert our ArrayChunked into a Series, ready to ship to\n// Python-land:\nOk(out.into_series())\n</code></pre> <p>That's it. What does the result look like? In <code>run.py</code>, we have:</p> <pre><code>import polars as pl\nfrom minimal_plugin import midpoint_2d\n\npoints = pl.Series(\n    \"points\",\n    [\n        [6.63, 8.35],\n        [7.19, 4.85],\n        [2.1, 4.21],\n        [3.4, 6.13],\n        [2.48, 9.26],\n        [9.41, 7.26],\n        [7.45, 8.85],\n        [6.58, 5.22],\n        [6.05, 5.77],\n        [8.57, 4.16],\n        [3.22, 4.98],\n        [6.62, 6.62],\n        [9.36, 7.44],\n        [8.34, 3.43],\n        [4.47, 7.61],\n        [4.34, 5.05],\n        [5.0, 5.05],\n        [5.0, 5.0],\n        [2.07, 7.8],\n        [9.45, 9.6],\n        [3.1, 3.26],\n        [4.37, 5.72],\n    ],\n    dtype=pl.Array(pl.Float64, 2),\n)\ndf = pl.DataFrame(points)\n\n# Now we call our plugin:\nresult = df.with_columns(midpoints=midpoint_2d(\"points\", ref_point=(5.0, 5.0)))\nprint(result)\n</code></pre> <p>Let's compile and run it: <pre><code>maturin develop\n\npython run.py\n</code></pre></p> <p>\ud83e\udd41: <pre><code>shape: (22, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 points        \u2506 midpoints      \u2502\n\u2502 ---           \u2506 ---            \u2502\n\u2502 array[f64, 2] \u2506 array[f64, 2]  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 [6.63, 8.35]  \u2506 [5.815, 6.675] \u2502\n\u2502 [7.19, 4.85]  \u2506 [6.095, 4.925] \u2502\n\u2502 [2.1, 4.21]   \u2506 [3.55, 4.605]  \u2502\n\u2502 [3.4, 6.13]   \u2506 [4.2, 5.565]   \u2502\n\u2502 [2.48, 9.26]  \u2506 [3.74, 7.13]   \u2502\n\u2502 \u2026             \u2506 \u2026              \u2502\n\u2502 [5.0, 5.0]    \u2506 [5.0, 5.0]     \u2502\n\u2502 [2.07, 7.8]   \u2506 [3.535, 6.4]   \u2502\n\u2502 [9.45, 9.6]   \u2506 [7.225, 7.3]   \u2502\n\u2502 [3.1, 3.26]   \u2506 [4.05, 4.13]   \u2502\n\u2502 [4.37, 5.72]  \u2506 [4.685, 5.36]  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <p>Note</p> <p>Notice how the dtype remains the same. As an exercise, try to achieve the same in pure-Python (without Rust plugins) without explicitly casting the type of the Series.</p> <p>Hurray, we did it! And why exactly go through all this trouble instead of just doing the same thing in pure Python? For performance of course!</p> <p>Spoilers ahead if you haven't tried the exercise from the note above</p> <p>With the following implementation in Python, we can take some measurements:</p> <pre><code>ref_point = (5.0, 5.0)\n\ndef using_plugin(df=df, ref_point=ref_point):\n    result = df.with_columns(midpoints=midpoint_2d(\"points\", ref_point=ref_point))\n    return result\n\ndef midpoint(points:pl.Series) -&gt; pl.Series:\n    result=[]\n    for point in points:\n        result.append([(point[0]+ref_point[0])/2, (point[1]+ref_point[1])/2])\n    return pl.Series(result, dtype=pl.Array(pl.Float64, 2))\n\ndef using_python(df=df, ref_point=ref_point):\n    result = (\n        df.with_columns(\n            midpoints=pl.col('points').map_batches(midpoint, return_dtype=pl.Array(pl.Float64, 2))\n        )\n    )\n    return result\n</code></pre> <p>For the sake of brevity, some extra methods to generate and parse an input file were left out of the code above, as  well as the <code>timeit</code> bits. By measuring both versions with 1.000.000 points a few times and taking the average, we got the following result:</p> <pre><code>Using plugin:\nmin: 0.5307095803339811\nmax: 0.5741689523274545\nmean +/- stderr: 0.5524565599986263 +/- 0.0064489015434971925\n\nUsing python:\nmin: 6.682447870339577\nmax: 6.99253460233255\nmean +/- stderr: 6.808615755191394 +/- 0.03757884107880601\n</code></pre> <p>A speedup of 12x, that's a big win!</p> <p>Note</p> <p>When benchmarking Rust code, remember to use <code>maturin develop --release</code>, otherwise the timings will be much slower!</p>"},{"location":"branch_mispredictions/","title":"7. Branch mispredictions","text":"<p>Time to go back to the past. In Section 2, I told you that the implementation we had of <code>abs_i64</code> wasn't the most efficient one you could possibly write. Time to see how to improve it!</p> <p>Which algorithm do you think would win?</p> <ol> <li>for each row:<ul> <li>check if it's null or not</li> <li>if it's not null, calculate its absolute value</li> </ul> </li> <li>for each row:<ul> <li>calculate its absolute value, even if we don't need it   because it's a null row</li> </ul> </li> </ol> <p>If you've not come across the concept of branch mispredictions before, then the answer may surprise you, because the second one is faster here. This is because <code>.abs</code> is a very fast operation, and wasting time checking whether each element is null or not actually slows us down!</p> <p>Here's how you can make <code>abs_i64</code> faster:</p> <pre><code>#[polars_expr(output_type=Int64)]\nfn abs_i64(inputs: &amp;[Series]) -&gt; PolarsResult&lt;Series&gt; {\n    let s = &amp;inputs[0];\n    let ca = s.i64()?;\n    let out = ca.apply_values(|x| x.abs());\n    Ok(out.into_series())\n}\n</code></pre> <p>For operations more complex than <code>.abs</code>, it may be that computing the operation for only the non-null values is cheaper. In general, you should measure, not guess. If you're just starting out with plugins and only need to beat <code>.map_elements</code>, then either of these solutions will blow it out of the water.</p> <p></p>"},{"location":"branch_mispredictions/#practice","title":"Practice!","text":"<p>Can you go back and make a faster version of <code>sum_i64</code>?</p>"},{"location":"cum_sum/","title":"4. Yes we SCAN","text":"<p>The operations we've seen so far have all been elementwise, e.g.:</p> <ul> <li>for each row, we calculated the absolute value</li> <li>for each row, we summed the respective values in two columns</li> </ul> <p>Let's do something (completely) different - instead of working with each row in isolation, we'll calculate a quantity which depends on the rows which precede it.</p> <p>We're going to implement <code>cum_sum</code>.</p>"},{"location":"cum_sum/#python-side","title":"Python side","text":"<p>Add this to <code>minimal_plugin/__init__.py</code>: <pre><code>def cum_sum(expr: IntoExprColumn) -&gt; pl.Expr:\n    return register_plugin_function(\n        args=[expr],\n        plugin_path=LIB,\n        function_name=\"cum_sum\",\n        is_elementwise=False,\n    )\n</code></pre> Note how, unlike in previous examples, we set <code>is_elementwise=False</code>. You'll see why this is so important at the end of this page.</p>"},{"location":"cum_sum/#rust","title":"Rust","text":"<p>Time to learn a new Rust function: <code>scan</code>. If you're not familiar with it, please take a little break from this tutorial and read the scan docs.</p> <p>Welcome back! Let's use our newfound scan-superpowers to implement <code>cum_sum</code>. Here's what goes into <code>src/expressions.rs</code>: <pre><code>#[polars_expr(output_type_func=same_output_type)]\nfn cum_sum(inputs: &amp;[Series]) -&gt; PolarsResult&lt;Series&gt; {\n    let s = &amp;inputs[0];\n    let ca: &amp;Int64Chunked = s.i64()?;\n    let out: Int64Chunked = ca\n        .iter()\n        .scan(0_i64, |state: &amp;mut i64, x: Option&lt;i64&gt;| {\n            match x {\n                Some(x) =&gt; {\n                    *state += x;\n                    Some(Some(*state))\n                },\n                None =&gt; Some(None),\n            }\n        })\n        .collect_trusted();\n    Ok(out.into_series())\n}\n</code></pre> Make sure to also add <pre><code>use pyo3_polars::export::polars_core::utils::CustomIterTools;\n</code></pre> to the top of the file.</p> <p>The <code>cum_sum</code> definition may look complex, but it's not too bad once we break it down:</p> <ul> <li>we hold the running sum in <code>state</code></li> <li>we iterate over rows, initialising <code>state</code> to be <code>0</code></li> <li>if the current row is <code>Some</code>, then add the current row's value to <code>state</code> and emit the current value of <code>state</code></li> <li>if the current row is <code>None</code>, then don't modify <code>state</code> and emit <code>None</code></li> </ul> <p>Note how we use <code>collect_trusted</code> at the end, rather than <code>collect</code>. <code>collect</code> would work as well, but if we know the length of the output (and we do in this case, <code>cum_sum</code> doesn't change the column's length) then we can safely use <code>collect_trusted</code> and save some precious time.</p> <p>Let's compile with <code>maturin develop</code> (or <code>maturin develop --release</code> if you're benchmarking), change the last line of <code>run.py</code> to <pre><code>print(df.with_columns(a_cum_sum=mp.cum_sum('a')))\n</code></pre> and then run <code>python run.py</code>:</p> <pre><code>shape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b    \u2506 a_cum_sum \u2502\n\u2502 --- \u2506 ---  \u2506 ---       \u2502\n\u2502 i64 \u2506 i64  \u2506 i64       \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 3    \u2506 1         \u2502\n\u2502 5   \u2506 null \u2506 6         \u2502\n\u2502 2   \u2506 -1   \u2506 8         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"cum_sum/#elementwise-my-dear-watson","title":"Elementwise, my dear Watson","text":"<p>Why was it so important to set <code>is_elementwise</code> correctly? Let's see with an example.</p> <p>Put the following in <code>run.py</code>: <pre><code>import polars as pl\nimport minimal_plugin as mp\n\ndf = pl.DataFrame({\n    'a': [1, 2, 3, 4, None, 5],\n    'b': [1, 1, 1, 2, 2, 2],\n})\nprint(df.with_columns(a_cum_sum=mp.cum_sum('a')))\n</code></pre></p> <p>Then, run <code>python run.py</code>.</p> <p>Finally, go to <code>minimal_plugin/__init__.py</code> and change <code>is_elementwise</code> from <code>False</code> to <code>True</code>, and run <code>python run.py</code> again.</p> <p>In both cases, you should see the following output: <pre><code>shape: (6, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a    \u2506 b   \u2506 a_cum_sum \u2502\n\u2502 ---  \u2506 --- \u2506 ---       \u2502\n\u2502 i64  \u2506 i64 \u2506 i64       \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 1   \u2506 1         \u2502\n\u2502 2    \u2506 1   \u2506 3         \u2502\n\u2502 3    \u2506 1   \u2506 6         \u2502\n\u2502 4    \u2506 2   \u2506 10        \u2502\n\u2502 null \u2506 2   \u2506 null      \u2502\n\u2502 5    \u2506 2   \u2506 15        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> which looks correct. So, what's the deal with <code>is_elementwise</code>?</p> <p>The deal is that we need it in order for window functions / <code>group_by</code>s to be correct. Change the last line of <code>run.py</code> to <pre><code>print(df.with_columns(a_cum_sum=mp.cum_sum('a').over('b')))\n</code></pre></p> <p>Now, we get:</p> <ul> <li> <p>with <code>elementwise=True</code>:</p> <pre><code>shape: (6, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a    \u2506 b   \u2506 a_cum_sum \u2502\n\u2502 ---  \u2506 --- \u2506 ---       \u2502\n\u2502 i64  \u2506 i64 \u2506 i64       \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 1   \u2506 1         \u2502\n\u2502 2    \u2506 1   \u2506 3         \u2502\n\u2502 3    \u2506 1   \u2506 6         \u2502\n\u2502 4    \u2506 2   \u2506 10        \u2502\n\u2502 null \u2506 2   \u2506 null      \u2502\n\u2502 5    \u2506 2   \u2506 15        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> </li> <li> <p>with <code>elementwise=False</code>:</p> <pre><code>shape: (6, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a    \u2506 b   \u2506 a_cum_sum \u2502\n\u2502 ---  \u2506 --- \u2506 ---       \u2502\n\u2502 i64  \u2506 i64 \u2506 i64       \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 1   \u2506 1         \u2502\n\u2502 2    \u2506 1   \u2506 3         \u2502\n\u2502 3    \u2506 1   \u2506 6         \u2502\n\u2502 4    \u2506 2   \u2506 4         \u2502\n\u2502 null \u2506 2   \u2506 null      \u2502\n\u2502 5    \u2506 2   \u2506 9         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> </li> </ul> <p>Only <code>elementwise=False</code> actually respected the window! This is why it's important to set <code>elementwise</code> correctly.</p>"},{"location":"life_pt1/","title":"Extra.1 Well...","text":"<p>\"No.\" - Doom Slayer</p> <p>Note</p> <p>This section is completely optional, and is provided for a bit of nerdy fun. It is by no means essential, feel free to skip it if it doesn't interest you!</p> <p>Well, someone can, probably. But doom in a dataframe would be kinda hard to play, so let's try something simpler. Conway's Game of Life is a notorious Cellular Automaton that we could perhaps implement with a plugin. For science, of course.</p> <p></p> <p>Jokes aside, life allows us to show how a plugin can access elements in both neighbouring rows and columns for each element. With a little bit of extra Python, we can display things in an almost pretty manner.</p> <p>Note</p> <p>For this tutorial, we'll assume you created a new plugin from the cookiecutter template and named it <code>game_of_life</code> (these steps aren't shown here, since they were already covered at the very beginning of this series).</p> <p>In this section we'll cover the developer side of the plugin (both Python and Rust). In the next section we'll show how a user can import and use what we developed here.</p>"},{"location":"life_pt1/#the-python-side","title":"The Python side","text":"<p>Let's take a look at what we'll implement first, in <code>game_of_life/__init__.py</code>:</p> <pre><code>import fileinput\nfrom collections import OrderedDict\nfrom itertools import tee, islice\nfrom os import PathLike\nfrom pathlib import Path\nfrom typing import Iterable, Any\n\nimport polars as pl\nfrom polars._typing import IntoExprColumn\nfrom polars.plugins import register_plugin_function\n\n\n# Parse a board from a file or stdin\ndef parse_board(ifile: str | ...) -&gt; list[list[int]]: ...\n\n# Transpose a list of lists\ndef _transpose(board: list[list[int]]) -&gt; list[list[int]]: ...\n\n# Creates a DataFrame from a list of lists\ndef board_to_df(board: list[list[int]]) -&gt; pl.DataFrame: ...\n\n# Helper function to help us deal with corner cases\ndef _nwise_wrapping(iterable: Iterable[Any], n: int): ...\n\n# Advance the simulation by n steps\ndef step(df: pl.DataFrame, n: int = 1): ...\n\n# Register our plugin\ndef life_step(left: IntoExprColumn, mid: IntoExprColumn, right: IntoExprColumn) -&gt; pl.Expr: ...\n</code></pre> <p>Starting with the function to parse a board from a file or stdin:</p> <pre><code>def parse_board(\n    ifile: (\n        str\n        | bytes\n        | PathLike[str]\n        | PathLike[bytes]\n        | Iterable[str | bytes | PathLike[str] | PathLike[bytes]]\n    ),\n) -&gt; list[list[int]]:\n    \"\"\"\n    Converts a board in a file containing only 0s and 1s, e.g.::\n\n        0010\n        0100\n\n    into:\n    [[0010],[0100]]\n    \"\"\"\n    return [\n        [c for ch in ln if (c := int(ch)) in [0, 1]]\n        for line in fileinput.input(ifile)\n        if len(ln := line.strip()) &gt; 0\n    ]\n</code></pre> <p>Next, we have transpose. Why do we need it, anyway? Because the way a dataframe reads our list of lists is counter-intuitive when constructing it from a dict comprehension. If we start with an input board like:</p> <pre><code>0000\n1111\n</code></pre> <p>without transpose, we'd end up with:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; board = [[0,0,0,0],[1,1,1,1]]\n&gt;&gt;&gt; pl.DataFrame({f\"c{idx}\": row for idx, row in enumerate(board)})\nshape: (4, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 c0  \u2506 c1  \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 0   \u2506 1   \u2502\n\u2502 0   \u2506 1   \u2502\n\u2502 0   \u2506 1   \u2502\n\u2502 0   \u2506 1   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Not what we expected visually, so we transpose the initial board to have the resulting dataframe match it.</p> <pre><code>def _transpose(board: list[list[int]]) -&gt; list[list[int]]:\n    return [[row[idx] for row in board] for idx in range(len(board[0]))]\n</code></pre> <p>Next one is <code>board_to_df</code>, which calls <code>_transpose</code> and constructs the DataFrame in a similar way to the example above. The padding detail is just to avoid columns with larger names than others, feel free to ignore it:</p> <pre><code>def board_to_df(board: list[list[int]]) -&gt; pl.DataFrame:\n    \"\"\"\n    Converts a list of lists of integers (0s and 1s) to a Polars DataFrame.\n    The inner lists must have the same length.\n    \"\"\"\n\n    # This is done because each row will become a column - the user likely\n    # expects a dataframe that *visually* matches the input file\n    board = _transpose(board)\n\n    padding_len = len(str(len(board) - 1))\n    board_t_dict = {f\"{idx:0{padding_len}}\": row for idx, row in enumerate(board)}\n    return pl.DataFrame(\n        board_t_dict,\n    )\n</code></pre> <p>Let's skip <code>_nwise_wrapping</code> and <code>step</code> for now and jump straight to the last function - we'll return to the two we skipped soon:</p> <p>Note</p> <p>Don't forget to read the comments!</p> <pre><code>def life_step(left: IntoExprColumn, mid: IntoExprColumn, right: IntoExprColumn) -&gt; pl.Expr:\n    \"\"\"\n    This is the function that registers the polars plugin. To use it directly,\n    data must be in the correct format. An interesting way to do so is to use\n    the same column names as the original data frame, so the resulting df will\n    have the same shape. See how this is done in the `step(df, n)` function.\n    \"\"\"\n    return register_plugin_function(\n        args=[left, mid, right],\n        plugin_path=LIB,\n        function_name=\"life_step\",\n        is_elementwise=False,\n    )\n</code></pre> <p>Ok, plugin registered. How do we use it? We create columns in <code>step</code> with <code>with_columns</code>. And we do so in a way that the new columns will have the exact name as the previously existing ones, so they're overridden.</p> <p>But wait, there's something we didn't talk about. What happens at the border of the board (both vertically and horizontally)? Do we stop the simulation from propagating there, do we wrap around, or something else? Many implementations stop the simulation at the border, so let's do it differently, let's wrap around!</p> <p>Wait, why are we talking about this here - isn't this a concern to be solved by our plugin in Rust? Yes, but Python-land is where we name our columns. So in order to have that nice overriding behavior, we need to address it here. This is also a hint at what the mysterious <code>_nwise_wrapping</code> function does:</p> <pre><code>def _nwise_wrapping(iterable: Iterable[Any], n: int):\n    \"\"\"\n    Returns overlapping n-tuples from an iterable, wrapping around. This means\n    the result will have the same length as `iterable`. It also  means the first\n    element(s) will include elements from the end of the iterable, and\n    likewise, the last element(s) will include elements from the start, e.g.::\n\n    fn('ABCDE', 3) -&gt; 'EAB', 'ABC', 'BCD', 'CDE', 'DEA'\n    \"\"\"\n    elements = list(iterable)\n    to_be_wrapped = elements[-(n - 2) :] + elements + elements[: n - 2]\n    iterators = tee(to_be_wrapped, n)\n    return [\n        list(z) for z in zip(*(islice(it, i, None) for i, it in enumerate(iterators)))\n    ]\n</code></pre> <p>The implementation might look a bit complicated, but the docstring should clarify its goal.</p> <p>Now we're only missing <code>step</code>, which takes a DataFrame already in the expected format and returns another DataFrame with our plugin applied <code>n</code> times to it:</p> <pre><code>def step(df: pl.DataFrame, n: int = 1):\n    \"\"\"\n    Takes a df and returns df.with_columns(...) corresponding to `n` advanced\n    steps in the simulation\n    \"\"\"\n    padding_len = len(str(df.width - 1))\n\n    # colnums: [['{n-1}', '00', '01'], ['00', '01', '02'], ['01', '02', '03'], ... ]\n    colnums = _nwise_wrapping([f\"{idx:0{padding_len}}\" for idx in range(df.width)], 3)\n\n    # colnames: ['00', '01', '02', '03', ... , '{n-1}']\n    colnames = [cols[1] for cols in colnums]\n\n    # colvalues: [&lt;Expr ['col(\"00\")./home/\u2026'] at 0x7B7C253C7E60&gt;, ... ]\n    colvalues = [life_step(*tuple(cols)) for cols in colnums]\n\n    for _ in range(n):\n        df = df.with_columns(**OrderedDict(zip(colnames, colvalues)))\n    return df\n</code></pre> <p>We're done with the Python side of things. And if you're wondering: \"what plugin did we actually register with <code>life_step</code>?\" - you're totally right to be confused, we didn't touch Rust yet! Why did we leave it for last? Because surprisingly, it's much simpler than the Python side, and much shorter too.</p>"},{"location":"life_pt1/#lets-get-rusty","title":"Let's get rusty","text":"<p>What do we need to do? For each element, we need to look at the the sum of the 8 neighbours, then apply the rule to decide whether the element will be dead or alive in the next iteration. Here's what our entire <code>src/expressions.rs</code> looks like:</p> <pre><code>#![allow(clippy::unused_unit)]\nuse polars::export::arrow::legacy::utils::CustomIterTools;\nuse polars::prelude::*;\nuse pyo3_polars::derive::polars_expr;\n\n#[polars_expr(output_type=Int64)]\nfn life_step(inputs: &amp;[Series]) -&gt; PolarsResult&lt;Series&gt; {\n    let (ca_lf, ca_curr, ca_rt) = (inputs[0].i64()?, inputs[1].i64()?, inputs[2].i64()?);\n\n    /*\n    We're \"counting\" on the user not to append or modify the DataFrame created\n    from the board file.\n\n    In general, this might sound insane, but for our Game of Life, this is not\n    so unreasonable.\n    */\n    let lf = ca_lf\n        .cont_slice()\n        .expect(\"Expected input to be contiguous (in a single chunk)\");\n    let mid = ca_curr\n        .cont_slice()\n        .expect(\"Expected input to be contiguous (in a single chunk)\");\n    let rt = ca_rt\n        .cont_slice()\n        .expect(\"Expected input to be contiguous (in a single chunk)\");\n\n    let len = lf.len();\n\n    let out: Int64Chunked = mid\n        .iter()\n        .enumerate()\n        .map(|(idx, val)| {\n            // Neighbours above\n            let prev_row = if 0 == idx {\n                lf[len - 1] + mid[len - 1] + rt[len - 1]\n            } else {\n                lf[idx - 1] + mid[idx - 1] + rt[idx - 1]\n            };\n\n            // Curr row does not include cell in the middle,\n            // a cell is not a neighbour of itself\n            let curr_row = lf[idx] + rt[idx];\n\n            // Neighbours below\n            let next_row = if len - 1 == idx {\n                lf[0] + mid[0] + rt[0]\n            } else {\n                lf[idx + 1] + mid[idx + 1] + rt[idx + 1]\n            };\n\n            // Life logic\n            Some(match (val, prev_row + curr_row + next_row) {\n                (1, 2) | (1, 3) =&gt; 1,\n                (0, 3) =&gt; 1,\n                _ =&gt; 0,\n            })\n        })\n        .collect_trusted();\n    Ok(out.into_series())\n}\n</code></pre> <p>Awesome, now what? If we ignore tests, as plugin developers, we could say we're done. Nothing's happened yet, so how could we be done? In the next section we'll take a look at how the plugin user would call the functions we made available.</p>"},{"location":"life_pt2/","title":"Extra.2 Plugin user","text":"<p>In the last section we saw what the plugin developers made available for a plugin user. Now we put the user's hat and demonstrate that usage. For this, we'll implement a CLI app that will parse a board file provided as an argument, then run a step of the simulation every <code>delay</code> seconds (also provided as an argument).</p> <p>Tip: place the code from this section in a separate file, e.g., <code>run.py</code>.</p> <p>Just like what we did previously, let's look at an overview of what's to come:</p> <pre><code>import argparse\nimport contextlib\nimport io\nimport sys\nfrom time import sleep\n\nfrom game_of_life import parse_board, board_to_df, step\nimport polars as pl\n\n\nclass Application:\n\n    # Initialize the board\n    def __init__(self): ...\n\n    # Printing the application object prints the board\n    def __str__(self) -&gt; str: ...\n\n    # Run a step of the simulation every `delay` steps, for `n` maximum steps\n    def start(self, n, delay, print_df): ...\n</code></pre> <p>Notice how we're importing <code>parse_board</code>, <code>board_to_df</code> and <code>step</code> from our fully-developed plugin. This could've been installed with pip! Check the publishing chapter for more on this.</p> <p>So first things first: <code>__init__</code>. Here we use the stdlib <code>argparse</code> module to capture the command line arguments we mentioned above. Then, we call <code>board_to_df</code> with the result of <code>parse_board</code>, storing the resulting DataFrame in the <code>Application</code> object itself.</p> <pre><code>class Application:\n\n    def __init__(self):\n        self._args = argparse.Namespace()\n        cli = argparse.ArgumentParser(\n            prog=\"python -m game_of_life\", description=\"Options\"\n        )\n        cli.add_argument(\"-i\", \"--input\", type=str, required=True)\n        cli.add_argument(\"-d\", \"--delay\", type=float, default=0.2)\n        cli.add_argument(\"-n\", \"--num-steps\", type=int, default=sys.maxsize)\n\n        cli.parse_args(namespace=self._args)\n\n        # [-i]\n        self.ifile: str = self._args.input\n\n        # [-d]\n        self.delay: float = self._args.delay\n\n        # [-n]\n        self.steps: int = self._args.num_steps\n\n        # Creates a pl.DataFrame from the provided file\n        self.df = board_to_df(parse_board(self.ifile))\n</code></pre> <p>Next, an optional but handy detail - we implement <code>__str__</code> for <code>Application</code> in a way that printing an <code>Application</code> object will actually print the DataFrame stored internally:</p> <pre><code>class Application:\n\n    # ...\n\n    def __str__(self) -&gt; str:\n        res = io.StringIO()\n        with (\n            pl.Config(tbl_rows=-1, tbl_cols=-1),\n            contextlib.redirect_stdout(res),\n        ):\n            print(self.df)\n        return res.getvalue()\n</code></pre> <p>The <code>pl.Config</code> part just removes the default row and column limits when displaying a DataFrame - otherwise we'd see ellipses (<code>...</code>) instead of <code>1</code>s and <code>0</code>s.</p> <p>Finally, <code>start</code> is where we display the DataFrame and call <code>step</code> to advance the simulation, over and over:</p> <pre><code>class Application:\n\n    # ...\n\n    def start(\n        self,\n        n: int | None = None,\n        delay: float | None = None,\n        print_df: bool = True,\n    ):\n        if n is None:\n            n = self.steps\n\n        if delay is None:\n            delay = self.delay\n\n        if print_df:\n            print(self)\n\n        iteration_cnt = 0\n        try:\n            for _ in range(n):\n                self.df = step(self.df)\n                iteration_cnt += 1\n                if print_df:\n                    # Clear screen\n                    print(\"\\033[2J\")\n                    print(self)\n                sleep(delay)\n\n        except KeyboardInterrupt:\n            print(\n                f\"\\nKeyboard Interrupt: ran for {iteration_cnt} iterations. Aborting...\"\n            )\n            print(f\"max_num_steps={self._args.num_steps}\\ndelay={self._args.delay}\")\n</code></pre> <p>To run the program, we only need two more things - an entry point and an input file. Create a <code>toad.txt</code> in an <code>input</code> folder, containing:</p> <pre><code>00000000000\n00000000000\n00000000000\n00001110000\n00011100000\n00000000000\n00000000000\n00000000000\n</code></pre> <p>and add this entry point at the end of <code>run.py</code>:</p> <pre><code>if __name__ == \"__main__\":\n    app = Application()\n    app.start()\n</code></pre> <p>Now we can see the results of our work, at last:</p> <pre><code># Compile the rust code\nmaturin develop --release\n\n# Run the application\npython run.py -i input/toad.txt -d 0.3\n</code></pre> <p></p> <p>Victory!</p>"},{"location":"life_pt2/#reference","title":"Reference","text":"<p>The entire code for this plugin, including the user's side, can be found on GitHub.</p>"},{"location":"lists/","title":"9.0 Weighted-mean watchers","text":"<p>According to one YouTube talk, the <code>list</code> namespace is one of Polars' main selling points. If you're also a fan of it, this section will teach you how to extend it even further.</p>"},{"location":"lists/#motivation","title":"Motivation","text":"<p>Say you have <pre><code>In [10]: df = pl.DataFrame({\n    ...:     'values': [[1, 3, 2], [5, 7]],\n    ...:     'weights': [[.5, .3, .2], [.1, .9]]\n    ...: })\n\nIn [11]: df\nOut[11]:\nshape: (2, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 values    \u2506 weights         \u2502\n\u2502 ---       \u2506 ---             \u2502\n\u2502 list[i64] \u2506 list[f64]       \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 [1, 3, 2] \u2506 [0.5, 0.3, 0.2] \u2502\n\u2502 [5, 7]    \u2506 [0.1, 0.9]      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <p>Can you calculate the mean of the values in <code>'values'</code>, weighted by the values in <code>'weights'</code>?</p> <p>So:</p> <ul> <li><code>.5*1 + .3*3 + .2*2 = 1.8</code></li> <li><code>5*.1 + 7*.9 = 6.8</code></li> </ul> <p>I don't know of an easy way to do this with Polars expressions. There probably is a way - but as you'll see here, it's not that hard to write a plugin, and it's probably faster too.</p>"},{"location":"lists/#weighted-mean","title":"Weighted mean","text":"<p>On the Python side, this'll be similar to <code>sum_i64</code>:</p> <pre><code>def weighted_mean(expr: IntoExprColumn, weights: IntoExprColumn) -&gt; pl.Expr:\n    return register_plugin_function(\n        args=[expr, weights],\n        plugin_path=LIB,\n        function_name=\"weighted_mean\",\n        is_elementwise=True,\n    )\n</code></pre> <p>On the Rust side, we'll define a helper function which will let us work with pairs of list chunked arrays:</p> <pre><code>fn binary_amortized_elementwise&lt;'a, T, K, F&gt;(\n    lhs: &amp;'a ListChunked,\n    rhs: &amp;'a ListChunked,\n    mut f: F,\n) -&gt; ChunkedArray&lt;T&gt;\nwhere\n    T: PolarsDataType,\n    T::Array: ArrayFromIter&lt;Option&lt;K&gt;&gt;,\n    F: FnMut(&amp;AmortSeries, &amp;AmortSeries) -&gt; Option&lt;K&gt; + Copy,\n{\n    {\n        let (lhs, rhs) = align_chunks_binary(lhs, rhs);\n        lhs.amortized_iter()\n            .zip(rhs.amortized_iter())\n            .map(|(lhs, rhs)| match (lhs, rhs) {\n                (Some(lhs), Some(rhs)) =&gt; f(&amp;lhs, &amp;rhs),\n                _ =&gt; None,\n            })\n            .collect_ca(PlSmallStr::EMPTY)\n    }\n}\n</code></pre> <p>That's a bit of a mouthful, so let's try to make sense of it.</p> <ul> <li>As we learned about in Prerequisites, Polars Series are backed by chunked arrays.   <code>align_chunks_binary</code> just ensures that the chunks have the same lengths. It may need   to rechunk under the hood for us;</li> <li><code>amortized_iter</code> returns an iterator of <code>AmortSeries</code>, each of which corresponds   to a row from our input.</li> </ul> <p>We'll explain more about <code>AmortSeries</code> in a future iteration of this tutorial. For now, let's just look at how to use this utility:</p> <ul> <li>we pass it <code>ListChunked</code> as inputs;</li> <li>we also pass a function which takes two <code>AmortSeries</code> and produces a scalar   value.</li> </ul> <pre><code>#[polars_expr(output_type=Float64)]\nfn weighted_mean(inputs: &amp;[Series]) -&gt; PolarsResult&lt;Series&gt; {\n    let values = inputs[0].list()?;\n    let weights = &amp;inputs[1].list()?;\n    polars_ensure!(\n        values.dtype() == &amp;DataType::List(Box::new(DataType::Int64)),\n        ComputeError: \"Expected `values` to be of type `List(Int64)`, got: {}\", values.dtype()\n    );\n    polars_ensure!(\n        weights.dtype() == &amp;DataType::List(Box::new(DataType::Float64)),\n        ComputeError: \"Expected `weights` to be of type `List(Float64)`, got: {}\", weights.dtype()\n    );\n\n    let out: Float64Chunked = binary_amortized_elementwise(\n        values,\n        weights,\n        |values_inner: &amp;AmortSeries, weights_inner: &amp;AmortSeries| -&gt; Option&lt;f64&gt; {\n            let values_inner = values_inner.as_ref().i64().unwrap();\n            let weights_inner = weights_inner.as_ref().f64().unwrap();\n            if values_inner.len() == 0 {\n                // Mirror Polars, and return None for empty mean.\n                return None\n            }\n            let mut numerator: f64 = 0.;\n            let mut denominator: f64 = 0.;\n            values_inner\n                .iter()\n                .zip(weights_inner.iter())\n                .for_each(|(v, w)| {\n                    if let (Some(v), Some(w)) = (v, w) {\n                        numerator += v as f64 * w;\n                        denominator += w;\n                    }\n                });\n            Some(numerator / denominator)\n        },\n    );\n    Ok(out.into_series())\n}\n</code></pre> <p>If you just need to get a problem solved, this function works! But let's note its limitations:</p> <ul> <li>it assumes that each inner element of <code>values</code> and <code>weights</code> has the same   length - it would be better to raise an error if this assumption is not met</li> <li>it only accepts <code>Int64</code> <code>values</code> and <code>Float64</code> <code>weights</code>   (see section 2 for how you could make it more generic).</li> </ul> <p>To try it out, we compile with <code>maturin develop</code> (or <code>maturin develop --release</code> if you're  benchmarking), and then we should be able to run <code>run.py</code>:</p> <p><pre><code>import polars as pl\nimport minimal_plugin as mp\n\ndf = pl.DataFrame({\n    'values': [[1, 3, 2], [5, 7]],\n    'weights': [[.5, .3, .2], [.1, .9]]\n})\nprint(df.with_columns(weighted_mean = mp.weighted_mean('values', 'weights')))\n</code></pre> to see <pre><code>shape: (2, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 values    \u2506 weights         \u2506 weighted_mean \u2502\n\u2502 ---       \u2506 ---             \u2506 ---           \u2502\n\u2502 list[i64] \u2506 list[f64]       \u2506 f64           \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 [1, 3, 2] \u2506 [0.5, 0.3, 0.2] \u2506 1.8           \u2502\n\u2502 [5, 7]    \u2506 [0.1, 0.9]      \u2506 6.8           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"lists/#gimme-chocolate-challenge","title":"Gimme chocolate challenge","text":"<p>Could you implement a weighted standard deviation calculator?</p>"},{"location":"lists_in_lists_out/","title":"9.1 Lists in, lists out, lists all about","text":"<p>Chapter 9.0 (Weighted-mean watchers) was fun. Let's do it all over again!</p> <p>Or rather, let's do another list operation. We're going to start with a dataframe such as:</p> <pre><code>shape: (4, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 dense        \u2502\n\u2502 ---          \u2502\n\u2502 list[i64]    \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 [0, 9]       \u2502\n\u2502 [8, 6, 0, 9] \u2502\n\u2502 null         \u2502\n\u2502 [3, 3]       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Before we start, however, let's take a look into how Polars stores lists in memory. As we saw, lists are backed up by chunks. Inside each chunk, Polars stores all the lists (\"rows\") as one single list, while keeping track of where each row starts, and how many elements they have. This is consistent with Apache Arrow's columnar format. It looks something like this:</p> <p></p> <p>Back to where we were - we're going to try to count the indices which are non-zero. \u2192</p> <p>Note</p> <p>You don't really need a plugin to do this, you can just do</p> <pre><code>df.with_columns(sparse_indices=pl.col('dense').list.eval(pl.arg_where(pl.element() != 0)))\n</code></pre> <p>But <code>eval</code> won't cover every need you ever have ever, so...it's good to learn how to do this as a plugin so you can then customize it according to your needs.</p> <p>Polars has a helper function built-in for dealing with this: <code>apply_amortized</code>. We can use it to apply a function to each element of a List Series. In this case, we just want to find the indices of non-zero elements, so we'll do:</p> <p><pre><code>fn list_idx_dtype(input_fields: &amp;[Field]) -&gt; PolarsResult&lt;Field&gt; {\n    let field = Field::new(input_fields[0].name.clone(), DataType::List(Box::new(IDX_DTYPE)));\n    Ok(field.clone())\n}\n\n#[polars_expr(output_type_func=list_idx_dtype)]\nfn non_zero_indices(inputs: &amp;[Series]) -&gt; PolarsResult&lt;Series&gt; {\n    let ca = inputs[0].list()?;\n    polars_ensure!(\n        ca.dtype() == &amp;DataType::List(Box::new(DataType::Int64)),\n        ComputeError: \"Expected `List(Int64)`, got: {}\", ca.dtype()\n    );\n\n    let out: ListChunked = ca.apply_amortized(|s| {\n        let s: &amp;Series = s.as_ref();\n        let ca: &amp;Int64Chunked = s.i64().unwrap();\n        let out: IdxCa = ca\n            .iter()\n            .enumerate()\n            .filter(|(_idx, opt_val)| opt_val != &amp;Some(0))\n            .map(|(idx, _opt_val)| Some(idx as IdxSize))\n            .collect_ca(PlSmallStr::EMPTY);\n        out.into_series()\n    });\n    Ok(out.into_series())\n}\n</code></pre> <code>apply_amortized</code> is a bit like the <code>apply_into_string_amortized</code> function we used in How to STRING something together, in that it makes a big allocation upfront to amortize the allocation costs. Think of it as a list version of <code>apply_values</code>, where each element is itself a <code>Series</code>.</p> <p>Something new in this example is:</p> <ul> <li><code>IdxSize</code></li> <li><code>IdxCa</code></li> <li><code>IDX_DTYPE</code></li> </ul> <p><code>IdxSize</code> is either <code>u32</code> or <code>u64</code>, depending on your platform, and are what Polars generally uses for counting-related operations. <code>IdxCa</code> is the associated <code>ChunkedArray</code>, and <code>IDX_DTYPE</code> the associated Polars dtype.</p> <p>To finish this off, the Python side will be a bog-standard:</p> <pre><code>def non_zero_indices(expr: IntoExprColumn) -&gt; pl.Expr:\n    return register_plugin_function(\n        args=[expr], plugin_path=LIB, function_name=\"non_zero_indices\", is_elementwise=True\n    )\n</code></pre> <p>If we then make <code>run.py</code> with</p> <p><pre><code>import polars as pl\nimport minimal_plugin as mp\n\npl.Config().set_fmt_table_cell_list_len(10)\n\ndf = pl.DataFrame({'dense': [[0, 9], [8, 6, 0, 9], None, [3, 3]]})\nprint(df)\nprint(df.with_columns(indices=mp.non_zero_indices('dense')))\n</code></pre> and compile with <code>maturin develop</code> (or <code>maturin develop --release</code> if you're benchmarking!) then we'll see</p> <pre><code>shape: (4, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 dense        \u2506 indices   \u2502\n\u2502 ---          \u2506 ---       \u2502\n\u2502 list[i64]    \u2506 list[u32] \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 [0, 9]       \u2506 [1]       \u2502\n\u2502 [8, 6, 0, 9] \u2506 [0, 1, 3] \u2502\n\u2502 null         \u2506 null      \u2502\n\u2502 [3, 3]       \u2506 [0, 1]    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Yay, it worked! And not only that, but it's about 1.5x as fast as the <code>list.eval</code> solution noted above!</p>"},{"location":"lost_in_space/","title":"12. Lost in space","text":"<p>Suppose, hypothetically speaking, that you're lost somewhere and only have access to your latitude, your longitude, and a laptop on which you can write a Polars Plugin. How can you find out what the closest city to you is?</p>"},{"location":"lost_in_space/#reverse-geocoding","title":"Reverse geocoding","text":"<p>The practice of starting with a (latitude, longitude) pair and finding out which city it corresponds to is known as reverse geocoding. We're not going to implement a reverse geocoder from scratch - instead, we'll use the <code>reverse-geocoder</code> crate and make a plugin out of it!</p>"},{"location":"lost_in_space/#cargo-here-cargo-there-cargo-everywhere","title":"Cargo here, cargo there, cargo everywhere","text":"<p>Let's add that crate to our project by running <code>cargo add reverse-geocoder</code>. You'll need to activate the nightly Rust channel, which you can do by making a file <code>rust-toolchain.toml</code> in your root directory <pre><code>[toolchain]\nchannel = \"nightly\"\n</code></pre> You'll also need to add <code>polars-arrow</code> and <code>polars-core</code> to <code>Cargo.toml</code> and pin them to the same version that you pin <code>polars</code> to. Yes, this example is getting a bit heavier...</p> <p>The way the <code>reverse-geocoder</code> crate works is:</p> <ul> <li>you instantiate a <code>ReverseGeocoder</code> instance</li> <li>you pass a (latitude, longitude) pair to <code>search</code></li> <li>you get the city name out</li> </ul> <p>So our plugin will work by taking two <code>Float64</code> columns (one of latitude, one for longitude) and producing a String output column.</p>"},{"location":"lost_in_space/#binary-elementwise-apply-to-buffer","title":"Binary elementwise apply to buffer","text":"<p>In How to STRING something together, we learned how to use <code>StringChunked.apply_into_string_amortized</code> to run an elementwise function on a String column. Does Polars have a binary version of that one which allows us to start from any data type?</p> <p>Unfortunately, not. But, this is a good chance to learn about a few new concepts!</p> <p>We'll start easy by dealing with the Python side. Add the following to <code>minimal_plugin/__init__.py</code>:</p> <pre><code>def reverse_geocode(lat: IntoExprColumn, long: IntoExprColumn) -&gt; pl.Expr:\n    return register_plugin_function(\n        args=[lat, long], plugin_path=LIB, function_name=\"reverse_geocode\", is_elementwise=True\n    )\n</code></pre> <p>On the Rust side, in <code>src/expressions.rs</code>, get ready for it, we're going to add:</p> <pre><code>use polars_arrow::array::MutablePlString;\nuse polars_core::utils::align_chunks_binary;\nuse reverse_geocoder::ReverseGeocoder;\n\n#[polars_expr(output_type=String)]\nfn reverse_geocode(inputs: &amp;[Series]) -&gt; PolarsResult&lt;Series&gt; {\n    let latitude = inputs[0].f64()?;\n    let longitude = inputs[1].f64()?;\n    let geocoder = ReverseGeocoder::new();\n    let out = binary_elementwise_into_string_amortized(latitude, longitude, |lhs, rhs, out| {\n        let search_result = geocoder.search((lhs, rhs));\n        write!(out, \"{}\", search_result.record.name).unwrap();\n    });\n    Ok(out.into_series())\n}\n</code></pre> <p>We use the utility function <code>binary_elementwise_into_string_amortized</code>, which is a binary version of <code>apply_into_string_amortized</code> which we learned about in the Stringify chapter.</p> <p>To run it, put the following in <code>run.py</code>: <pre><code>import polars as pl\nimport minimal_plugin as mp\n\ndf = pl.DataFrame({\n    'lat': [37.7749, 51.01, 52.5],\n    'lon': [-122.4194, -3.9, -.91]\n})\nprint(df.with_columns(city=mp.reverse_geocode('lat', 'lon')))\n</code></pre> then compile with <code>maturin develop</code> (or <code>maturin develop --release</code> if you're benchmarking) and you should see <pre><code>shape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 lat     \u2506 lon       \u2506 city              \u2502\n\u2502 ---     \u2506 ---       \u2506 ---               \u2502\n\u2502 f64     \u2506 f64       \u2506 str               \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 37.7749 \u2506 -122.4194 \u2506 San Francisco     \u2502\n\u2502 51.01   \u2506 -3.9      \u2506 South Molton      \u2502\n\u2502 52.5    \u2506 -0.91     \u2506 Market Harborough \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> in the output!</p> <p>Great, now in our hypothetical scenario, you're probably still lost, but at least you know which city you're closest to.</p>"},{"location":"noop/","title":"1. How to do nothing","text":"<p>That's right - this section is about how to do nothing.</p> <p>We'll write a Polars plugin which takes an expression, and returns it exactly as it is. Nothing more, nothing less. This will just be an exercise in setting everything up!</p> <p>If you followed the instructions in Prerequisites, then your working directory should look a bit like the following: <pre><code>.\n\u251c\u2500\u2500 Cargo.toml\n\u251c\u2500\u2500 minimal_plugin\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 typing.py\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 run.py\n\u251c\u2500\u2500 src\n\u2502   \u251c\u2500\u2500 expressions.rs\n\u2502   \u2514\u2500\u2500 lib.rs\n\u2514\u2500\u2500 tests\n</code></pre> The cookiecutter command you ran earlier set up a Polars plugin project with a  sample function called <code>pig_latinnify</code> already implemented. The Polars Plugins Cookiecutter  helps you quickly start a Polars plugin project, skipping the boilerplate setup.  Check it out for more details!</p>"},{"location":"noop/#the-python-side","title":"The Python side","text":"<p>Let's start by getting the Python side ready. It won't run until we implement the Rust side too, but it's a necessary step. Start by adding the following to <code>minimal_plugin/__init__.py</code>:</p> <p><pre><code>def noop(expr: IntoExprColumn) -&gt; pl.Expr:\n    return register_plugin_function(\n        args=[expr],\n        plugin_path=LIB,\n        function_name=\"noop\",\n        is_elementwise=True,\n    )\n</code></pre> Let's go through this line-by-line:</p> <ul> <li>when we compile Rust, it generates a Shared Object file.   The <code>LIB</code> variable holds its filepath;</li> <li>We'll cover <code>is_elementwise</code> in Yes we SCAN, for now don't pay attention to it;</li> <li>We use the Polars utility function register_plugin_function to extend its functionality with our own.</li> </ul> <p>Note that string literals are parsed as expressions, so that if somebody calls <code>noop('a')</code>, it gets interpreted as <code>noop(pl.col('a'))</code>.</p>"},{"location":"noop/#lets-get-rusty","title":"Let's get Rusty","text":"<p>Let's leave <code>src/lib.rs</code> as it is, and add the following to <code>src/expressions.rs</code>:</p> <pre><code>fn same_output_type(input_fields: &amp;[Field]) -&gt; PolarsResult&lt;Field&gt; {\n    let field = &amp;input_fields[0];\n    Ok(field.clone())\n}\n\n#[polars_expr(output_type_func=same_output_type)]\nfn noop(inputs: &amp;[Series]) -&gt; PolarsResult&lt;Series&gt; {\n    let s = &amp;inputs[0];\n    Ok(s.clone())\n} \n</code></pre> <p>There's a lot to cover here so we'll break it down below.</p>"},{"location":"noop/#defining-noops-schema","title":"Defining <code>noop</code>'s schema","text":"<p>Polars needs to know the schema/dtypes resulting from operations to make good optimization decisions. The way we tell Polars what to expect from our custom function is with the <code>polars_expr</code> attribute.</p> <p>Our beautiful <code>noop</code> doesn't change the data type (in fact, it doesn't change anything...) so we'll just write a function which returns the same input type:</p> <p><pre><code>fn same_output_type(input_fields: &amp;[Field]) -&gt; PolarsResult&lt;Field&gt; {\n    let field = &amp;input_fields[0];\n    Ok(field.clone())\n}\n</code></pre> and use that to define the function output's schema. Just like <code>noop</code>, this function takes a reference to its only input and clones it.</p>"},{"location":"noop/#defining-noops-body","title":"Defining <code>noop</code>'s body","text":"<p>The input is an iterable of <code>Series</code>. In our case, <code>noop</code> just receives a single Series as input, but as we'll see in later sections, it's possible to pass multiple Series.</p> <p>We said we wanted our function to do nothing, so let's implement that: take a reference to the first (and only) input Series, and return a (cheap!) clone of it.</p>"},{"location":"noop/#putting-it-all-together","title":"Putting it all together","text":"<p>Right, does this all work? Let's edit the Python file <code>run.py</code>,  which we will use for testing. We'll just make a toy dataframe  and apply <code>noop</code> to each column! <pre><code>import polars as pl\nimport minimal_plugin as mp\n\ndf = pl.DataFrame({\n    'a': [1, 1, None],\n    'b': [4.1, 5.2, 6.3],\n    'c': ['hello', 'everybody!', '!']\n})\nprint(df.with_columns(mp.noop(pl.all()).name.suffix('_noop')))\n</code></pre></p> <p>Let's compile! Please run <code>maturin develop</code> (or <code>maturin develop --release</code> if benchmarking). You'll need to do this every time you change any of your Rust code. It may take a while the first time, but subsequent executions will be significantly faster as the build process is incremental.</p> <p>Finally, you can run your code! If you run <code>python run.py</code> and get the following output: <pre><code>shape: (3, 6)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a    \u2506 b   \u2506 c          \u2506 a_noop \u2506 b_noop \u2506 c_noop     \u2502\n\u2502 ---  \u2506 --- \u2506 ---        \u2506 ---    \u2506 ---    \u2506 ---        \u2502\n\u2502 i64  \u2506 f64 \u2506 str        \u2506 i64    \u2506 f64    \u2506 str        \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 4.1 \u2506 hello      \u2506 1      \u2506 4.1    \u2506 hello      \u2502\n\u2502 1    \u2506 5.2 \u2506 everybody! \u2506 1      \u2506 5.2    \u2506 everybody! \u2502\n\u2502 null \u2506 6.3 \u2506 !          \u2506 null   \u2506 6.3    \u2506 !          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> then it means everything worked correctly. Congrats!</p> <p>You're now ready to learn how to do ABSolutely nothing.</p>"},{"location":"prerequisites/","title":"0. Prerequisites","text":""},{"location":"prerequisites/#knowledge","title":"Knowledge","text":"<p>\"But you know what I like more than materialistic things? Knowledge.\" Tai Lopez</p> <p>How much Rust do you need to know to write your own Polars plugin? Less than you think.</p> <p>I'd suggest starting out with the Rustlings course, which provides some fun and interactive exercises designed to make you familiar with the language. I'd suggest starting the following sections:</p> <ul> <li>00 intro</li> <li>01 variables</li> <li>02 functions</li> <li>03 if</li> <li>05 vecs</li> <li>12 options</li> <li>13 error handling</li> </ul> <p>You'll also need basic Python knowledge: classes, decorators, and functions.</p> <p>Alternatively, you could just clone this repo and then hack away at the examples trial-and-error style until you get what you're looking for - the compiler will probably help you more than you're expecting.</p>"},{"location":"prerequisites/#software","title":"Software","text":"<p>To get started, please install cookiecutter.</p> <p>Then, from your home directory (or wherever you store your Python projects) please run <pre><code>cookiecutter https://github.com/MarcoGorelli/cookiecutter-polars-plugins\n</code></pre> When prompted, please enter (let's suppose your name is \"Maja Anima\", but replace that with your preferred name): <pre><code>[1/3] plugin_name (Polars Cookiecutter): Minimal Plugin\n[2/3] project_slug (polars_minimal_plugin):\n[3/3] author (anonymous): Maja Anima\n</code></pre> This will create a folder call <code>minimal_plugin</code>. Please navigate to it with <code>cd minimal_plugin</code>.</p> <p>Next, create a Python3.8+ virtual environment, and install:</p> <ul> <li><code>polars&gt;=1.3.0</code></li> <li><code>maturin&gt;=1.4.0</code></li> </ul> <p>Finally, you'll also need to install Rust.</p> <p>That's it! However, you are highly encouraged to also install rust-analyzer if you want to improve your Rust-writing experience by exactly 120%.</p>"},{"location":"prerequisites/#whats-in-a-series","title":"What's in a Series?","text":"<p>If you take a look at a Series such as <pre><code>In [9]: s = pl.Series([None, 2, 3]) + 42\n\nIn [10]: s\nOut[10]:\nshape: (3,)\nSeries: '' [i64]\n[\n        null\n        44\n        45\n]\n</code></pre> you may be tempted to conclude that it contains three values: <code>[null, 44, 45]</code>.</p> <p>However, if you print out <code>s._get_buffers()</code>, you'll see something different:</p> <ul> <li><code>s._get_buffers()[\"values\"]</code>: <code>[42, 44, 45]</code>. These are the values.</li> <li><code>s._get_buffers()[\"validity\"]</code>: <code>[False, True, True]</code>. These are the validities.</li> </ul> <p>So we don't really have integers and <code>null</code> mixed together into a single array - we have a pair of arrays, one holding values and another one holding booleans indicating whether each value is valid or not. If a value appears as <code>null</code> to you, then there's no guarantee about what physical number is behind it! It was <code>42</code> here, but it could well be <code>43</code>, or any other number, in another example.</p>"},{"location":"prerequisites/#whats-a-chunk","title":"What's a chunk?","text":"<p>A Series is backed by chunked arrays, each of which holds data which is contiguous in memory.</p> <p>Here's an example of a Series backed  by multiple chunks: <pre><code>In [27]: s = pl.Series([1,2,3])\n\nIn [28]: s = s.append(pl.Series([99, 11]))\n\nIn [29]: s\nOut[29]:\nshape: (5,)\nSeries: '' [i64]\n[\n        1\n        2\n        3\n        99\n        11\n]\n\nIn [30]: s.get_chunks()\nOut[30]:\n[shape: (3,)\n Series: '' [i64]\n [\n        1\n        2\n        3\n ],\n shape: (2,)\n Series: '' [i64]\n [\n        99\n        11\n ]]\n</code></pre> Chunked arrays will come up in several examples in this tutorial.</p>"},{"location":"publishing/","title":"14. Publishing your plugin to PyPI and becoming famous","text":"<p>Here are the steps you should follow:</p> <ol> <li>publish plugin to PyPI</li> <li>???</li> <li>profit</li> </ol> <p>This section deals with step 1, and assumes your project live on GitHub.</p>"},{"location":"publishing/#set-up-trusted-publishing","title":"Set up trusted publishing","text":"<p>If you followed the Prerequisites steps, you should have <code>.github/workflows/publish_to_pypi.yml</code>, <code>Makefile</code>, and <code>requirements.txt</code> files. If not, go back and follow the cookiecutter step.</p> <p>Next, set up an account on Pypi.org, can't do much without that.</p> <p>Third, on PyPI, you'll want to (note: this is taken almost verbatim from PyPA):</p> <ol> <li>Go to https://pypi.org/manage/account/publishing/.</li> <li>Fill in the name you wish to publish your new PyPI project under (the name value in your pyproject.toml), the GitHub repository owner\u2019s name (org or user), and repository name, and the name of the release workflow file under the .github/ folder, see Creating a workflow definition. Finally, add the name of the GitHub Environment (pypi) we\u2019re going set up under your repository. Register the trusted publisher.</li> </ol> <p>Finally, if you make a commit and tag it, and then push, then a release should be triggered! It will then be available for install across different platforms, which would be really hard (impossible?) to do if you were building the wheel manually and uploading to PyPI yourself.</p>"},{"location":"publishing/#pypi_api_token","title":"PYPI_API_TOKEN","text":"<p>You'll also need a repository secret called <code>PYPI_API_TOKEN</code>. In PyPI, create an API token scoped just to your project, and then save it in your repository's secrets using the name <code>PYPI_API_TOKEN</code>.</p>"},{"location":"stem/","title":"6. How to CRATE something else entirely","text":"<p>Take a look at crates.io - there's so much good stuff there! There's probably a package for practically any use case.</p> <p>For example, this looks like a fun one: rust_stemmers. It lets us input a word, and stem it (i.e. reduce it to a simpler version, e.g. 'fearlessly' -&gt;  'fearless'). Can we make a plugin out of it?</p>"},{"location":"stem/#cargo-this-cargo-that","title":"Cargo this, cargo that","text":"<p>If we're going to use <code>rust_stemmers</code>, we're going to need to take it on as a dependency. The easiest way to do this is probably to run <code>cargo add rust_stemmers</code> - run this, and watch how <code>Cargo.toml</code> changes! You should see the line <pre><code>rust-stemmers = \"1.2.0\"\n</code></pre> somewhere in there.</p>"},{"location":"stem/#writing-a-snowball-stemmer","title":"Writing a Snowball Stemmer","text":"<p>Let's write a function which:</p> <ul> <li>takes a <code>Utf8</code> columns as input;</li> <li>produces a <code>Utf8</code> column as output.</li> </ul> <p>We'd like to be able to call it as follows:</p> <pre><code>df.with_columns(stemmed_word=mp.snowball_stem('word'))\n</code></pre> <p>On the Python side, let's add the following function to <code>minimal_plugin/__init__.py</code>:</p> <pre><code>def snowball_stem(expr: IntoExprColumn) -&gt; pl.Expr:\n    return register_plugin_function(\n        args=[expr],\n        plugin_path=LIB,\n        function_name=\"snowball_stem\",\n        is_elementwise=True,\n    )\n</code></pre> <p>Then, we can define the function like this in <code>src/expressions.rs</code>:</p> <pre><code>use rust_stemmers::{Algorithm, Stemmer};\n\n#[polars_expr(output_type=String)]\nfn snowball_stem(inputs: &amp;[Series]) -&gt; PolarsResult&lt;Series&gt; {\n    let ca: &amp;StringChunked = inputs[0].str()?;\n    let en_stemmer = Stemmer::create(Algorithm::English);\n    let out: StringChunked = ca.apply_into_string_amortized(|value: &amp;str, output: &amp;mut String| {\n        write!(output, \"{}\", en_stemmer.stem(value)).unwrap()\n    });\n    Ok(out.into_series())\n}\n</code></pre> <p>Let's try it out! Put the following in <code>run.py</code>: <pre><code>import polars as pl\nimport minimal_plugin as mp\n\ndf = pl.DataFrame({'word': [\"fearlessly\", \"littleness\", \"lovingly\", \"devoted\"]})\nprint(df.with_columns(b=mp.snowball_stem('word')))\n</code></pre></p> <p>If you then compile with <code>maturin develop</code> (or <code>maturin develop --release</code> if you're benchmarking), and run it with <code>python run.py</code>, you'll see: <pre><code>shape: (4, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a          \u2506 b        \u2502\n\u2502 ---        \u2506 ---      \u2502\n\u2502 str        \u2506 str      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 fearlessly \u2506 fearless \u2502\n\u2502 littleness \u2506 littl    \u2502\n\u2502 lovingly   \u2506 love     \u2502\n\u2502 devoted    \u2506 devot    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <p>In this example, we took on an extra dependency, which increased the size of the package. By using plugins, we have a way of accessing extra functionality without having to bloat up the size of the main Polars install too much!</p>"},{"location":"stem/#stretch-goal","title":"Stretch goal","text":"<p>Browse through <code>crates.io</code> - is there any other crate you could use to make your own plugin out of?</p>"},{"location":"stringify/","title":"5. How to STRING something together","text":"<p>Tired of examples which only include numeric data? Me neither. But we need to address the elephant in the room: strings.</p> <p>We're going to start by re-implementing a pig-latinnifier. This example is already part of the <code>pyo3-polars</code> repo examples, but we'll tackle it with a different spin here by first doing it the wrong way \ud83d\ude08.</p>"},{"location":"stringify/#pig-latinnify-take-1","title":"Pig-latinnify - take 1","text":"<p>Let's start by doing this the wrong way. We'll use our <code>abs</code> example, and adapt it to the string case. We'll follow the same strategy:</p> <ul> <li>iterate over arrow arrays;</li> <li>for each element in each array, create a new output value.</li> </ul> <p>Put the following in <code>src/expressions.rs</code>:</p> <p><pre><code>use std::borrow::Cow;\nuse std::fmt::Write;\n\n#[polars_expr(output_type=String)]\nfn pig_latinnify(inputs: &amp;[Series]) -&gt; PolarsResult&lt;Series&gt; {\n    let s = &amp;inputs[0];\n    let ca = s.str()?;\n    let out: StringChunked = ca.apply(|opt_v: Option&lt;&amp;str&gt;| {\n        opt_v.map(|value: &amp;str| {\n            // Not the recommended way to do it,\n            // see below for a better way!\n            if let Some(first_char) = value.chars().next() {\n                Cow::Owned(format!(\"{}{}ay\", &amp;value[1..], first_char))\n            } else {\n                Cow::Borrowed(value)\n            }\n        })\n    });\n    Ok(out.into_series())\n}\n</code></pre> If you're not familiar with clone-on-write, don't worry about it - we're about to see a simpler and better way to do this anyway. What I'd like you to focus on is that for every row, we're creating a new <code>String</code>.</p> <p>If you combine this with a Python definition (which you should put in <code>minimal_plugin/__init__.py</code>):</p> <p><pre><code>def pig_latinnify(expr: IntoExprColumn) -&gt; pl.Expr:\n    return register_plugin_function(\n        args=[expr],\n        plugin_path=LIB,\n        function_name=\"pig_latinnify\",\n        is_elementwise=True,\n    )\n</code></pre> then you'll be able to pig-latinnify a column of strings! To see it in action, compile with <code>maturin develop</code> (or <code>maturin develop --release</code> if you're benchmarking) and put the following in <code>run.py</code>:</p> <p><pre><code>import polars as pl\nimport minimal_plugin as mp\n\ndf = pl.DataFrame({'a': [\"I\", \"love\", \"pig\", \"latin\"]})\nprint(df.with_columns(a_pig_latin=mp.pig_latinnify('a')))\n</code></pre> <pre><code>shape: (4, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a     \u2506 a_pig_latin \u2502\n\u2502 ---   \u2506 ---         \u2502\n\u2502 str   \u2506 str         \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 I     \u2506 Iay         \u2502\n\u2502 love  \u2506 ovelay      \u2502\n\u2502 pig   \u2506 igpay       \u2502\n\u2502 latin \u2506 atinlay     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <p>This will already be an order of magnitude faster than using <code>map_elements</code>. But as mentioned earlier, we're creating a new string for every single row.</p> <p>Can we do better?</p>"},{"location":"stringify/#pig-latinnify-take-2","title":"Pig-latinnify - take 2","text":"<p>Yes! <code>StringChunked</code> has a utility <code>apply_into_string_amortized</code> method which amortises the cost of creating new strings for each row by creating a string upfront, clearing it, and repeatedly writing to it. This gives a 4x speedup! All you need to do is change <code>pig_latinnify</code> to:</p> <pre><code>#[polars_expr(output_type=String)]\nfn pig_latinnify(inputs: &amp;[Series]) -&gt; PolarsResult&lt;Series&gt; {\n    let ca: &amp;StringChunked = inputs[0].str()?;\n    let out: StringChunked = ca.apply_into_string_amortized(|value: &amp;str, output: &amp;mut String| {\n        if let Some(first_char) = value.chars().next() {\n            write!(output, \"{}{}ay\", &amp;value[1..], first_char).unwrap()\n        }\n    });\n    Ok(out.into_series())\n}\n</code></pre> <p>Simpler, faster, and more memory-efficient. Thinking about allocations can really make a difference!</p>"},{"location":"stringify/#so-lets-think-about-allocations","title":"So let's think about allocations!","text":"<p>If you have an elementwise function which produces <code>String</code> output, then chances are it does one of the following:</p> <ul> <li>Creates a new string. In this case, you can use <code>apply_into_string_amortized</code> to amortise the cost of allocating a new string for each input row,   as we did above in <code>pig_latinnify</code>. This works by allocating a <code>String</code> upfront and then repeatedly re-writing to it.</li> <li> <p>Slices the original string. In this case, you can use <code>apply_values</code> with <code>Cow::Borrowed</code>, for example:</p> <pre><code>fn remove_last_extension(s: &amp;str) -&gt; &amp;str {\n    match s.rfind('.') {\n        Some(pos) =&gt; &amp;s[..pos],\n        None =&gt; s,\n    }\n}\n\n#[polars_expr(output_type=String)]\nfn remove_extension(inputs: &amp;[Series]) -&gt; PolarsResult&lt;Series&gt; {\n    let s = &amp;inputs[0];\n    let ca = s.str()?;\n    let out: StringChunked = ca.apply_values(|val| {\n        let res = Cow::Borrowed(remove_last_extension(val));\n        res\n    });\n    Ok(out.into_series())\n}\n</code></pre> </li> </ul> <p>There are low-level optimisations you can do to take things further, but - if in doubt - <code>apply_into_string_amortized</code> / <code>binary_elementwise_into_string_amortized</code> are probably good enough.</p>"},{"location":"struct/","title":"10. STRUCTin'","text":"<p>\"Day one, I'm in love with your struct\" Thumpasaurus (kinda)</p> <p>For this chapter, we need to start by activating the necessary feature - in <code>Cargo.toml</code>, please make this change:</p> <pre><code>-polars = { version = \"0.49.1\", default-features = false }\n+polars = { version = \"0.49.1\", features=[\"dtype-struct\"], default-features = false }\n</code></pre> <p>How do we consume structs, and how do we return them?</p> <p>Let's try creating a Polars DataFrame in Python that stores a struct similar to this one:</p> <pre><code>struct Point2D {\n    x: f64,\n    y: f64,\n    rgb: u32,\n}\n</code></pre> <p></p> <p>There are different ways of doing that, but that doesn't matter now. Here's one way: <pre><code>df = pl.DataFrame(\n    {\n        \"x\": [1.0, 1.25, 1.5, 1.75],\n        \"y\": [3.0, 2.75, 2.5, 2.25],\n        \"rgba\": [0x00FF7FFF, 0xFF7F00FF, 0x7F7F7FFF, 0xD8D8D8FF],\n    }\n).select(\n    point_2d_s=pl.struct(\n        \"x\", \"y\", \"rgba\",\n        schema={\n            \"x\": pl.Float64,\n            \"y\": pl.Float64,\n            \"rgba\": pl.UInt32,\n        }\n    )\n)\n</code></pre></p> <p>If we <code>print(df)</code>, here's what we have:</p> <pre><code>shape: (4, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 point_2d_s             \u2502\n\u2502 ---                    \u2502\n\u2502 struct[3]              \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 {1.0,3.0,16744447}     \u2502\n\u2502 {1.25,2.75,4286513407} \u2502\n\u2502 {1.5,2.5,2139062271}   \u2502\n\u2502 {1.75,2.25,3638089983} \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Now's an excellent time to ask: how's that stored in memory? Before we get to that answer, consider this other scenario, in Rust:</p> <pre><code>let v: [Point2D; 4] = [\n    Point2D {\n        x: 1.0,\n        y: 3.0,\n        rgb: 0x00FF7FFFu32,\n    },\n    Point2D {\n        x: 1.25,\n        y: 2.75,\n        rgb: 0xFF7F00FFu32,\n    },\n    Point2D {\n        x: 1.5,\n        y: 2.5,\n        rgb: 0x7F7F7FFFu32,\n    },\n    Point2D {\n        x: 1.75,\n        y: 2.25,\n        rgb: 0xD8D8D8FFu32,\n    },\n];\n</code></pre> <p>How's this one stored in memory? You might find that answer easier, it's an array of struct instances, so we have the <code>x</code>, <code>y</code> and <code>rgba</code> fields contiguously in memory, like that:</p> <p></p> <p>This is consistent with how C, C++, and many other languages store structs in memory. How's our struct-in-a-DataFrame different?</p> <p>Polars follows the Arrow protocol for structs, which means each field of the struct is stored in a Series, backed by chunks. Each chunk is contiguous in memory. In a scenario in which we have a single chunk for each field, this is how things would look like:</p> <p></p> <p>Since we never modified the DataFrame after creating it, it is the case of our initial example, no more chunks were allocated.</p> <p>Now that we have a better idea of how things work under the hood, let's jump to a practical plugin that takes a struct, and just prints the Series corresponding to each field - it'll return the same struct passed as input, with no alteration.</p> <p>First things first - this time we're gonna see somthing new. Polars does not allow us to write:</p> <pre><code>#[polars_expr(output_type=Struct)]\nfn print_struct_fields(inputs: &amp;[Series]) -&gt; PolarsResult&lt;Series&gt; { ... }\n</code></pre> <p>The way we inform a struct Series is being returned is a bit cumbersome - we do so by defining a separate function:</p> <pre><code>fn struct_point_2d_output(input_fields: &amp;[Field]) -&gt; PolarsResult&lt;Field&gt; {\n    let field = &amp;input_fields[0];\n    match field.dtype() {\n        DataType::Struct(fields) =&gt; {\n            Ok(Field::new(\"struct_point_2d\".into(), DataType::Struct(fields.clone())))\n        }\n        dtype =&gt; polars_bail!(InvalidOperation: \"expected Struct dtype, got {}\", dtype),\n    }\n}\n</code></pre> <p>Then using that function in our <code>polars_expr</code>, with a different \"kwarg\":</p> <pre><code>#[polars_expr(output_type_func=struct_point_2d_output)]\nfn print_struct_fields(inputs: &amp;[Series]) -&gt; PolarsResult&lt;Series&gt; {\n\n    let struct_ = inputs[0].struct_()?;\n    let fields = struct_.fields_as_series();\n\n    if fields.is_empty() {\n        return Ok(inputs[0].clone());\n    }\n\n    let fields = fields\n        .iter()\n        .map(|s| {\n            let s = s.clone();\n            println!(\"{:?}\", s);\n            s\n        })\n        .collect::&lt;Vec&lt;_&gt;&gt;();\n\n    StructChunked::from_series(struct_.name().clone(), struct_.len(), fields.iter())\n        .map(|ca| ca.into_series())\n}\n</code></pre> <p>This is a very basic, \"do-nothing\" example. For this reason, we're not gonna spend too much time here. Still, you're encouraged to register the plugin and try it for yourself, as an exercise.</p> <p>Now, let's look at something more interesting.</p> <p>We'll rewrite a plugin which takes a <code>Struct</code> as input, and shifts all values forwards by one key. So, for example, if the input was <code>{'a': 1, 'b': 2., 'c': '3'}</code>, then the output will be <code>{'a': 2., 'b': '3', 'c': 1}</code>.</p> <p>On the Python side, usual business:</p> <pre><code>def shift_struct(expr: IntoExprColumn) -&gt; pl.Expr:\n    return register_plugin_function(\n        args=[expr],\n        plugin_path=LIB,\n        function_name=\"shift_struct\",\n        is_elementwise=True,\n    )\n</code></pre> <p>Then, we need to get the schema right.</p> <pre><code>fn shifted_struct(input_fields: &amp;[Field]) -&gt; PolarsResult&lt;Field&gt; {\n    let field = &amp;input_fields[0];\n    match field.dtype() {\n        DataType::Struct(fields) =&gt; {\n            let mut field_0 = fields[0].clone();\n            let name = field_0.name.clone();\n            field_0.set_name(fields[fields.len() - 1].name().clone());\n            let mut fields = fields[1..]\n                .iter()\n                .zip(fields[0..fields.len() - 1].iter())\n                .map(|(fld, name)| Field::new(name.name().clone(), fld.dtype().clone()))\n                .collect::&lt;Vec&lt;_&gt;&gt;();\n            fields.push(field_0);\n            Ok(Field::new(name, DataType::Struct(fields)))\n        }\n        _ =&gt; unreachable!(),\n    }\n}\n</code></pre> <p>In this case, I put the first field's name as the output struct's name, but it doesn't really matter what we put, as Polars doesn't allow us to rename expressions within plugins. You can always rename on the Python side if you really want to, but I'd suggest to just let Polars follow its usual \"left-hand-rule\".</p> <p>The function definition is going to follow a similar logic:</p> <pre><code>#[polars_expr(output_type_func=shifted_struct)]\nfn shift_struct(inputs: &amp;[Series]) -&gt; PolarsResult&lt;Series&gt; {\n    let struct_ = inputs[0].struct_()?;\n    let fields = struct_.fields_as_series();\n    if fields.is_empty() {\n        return Ok(inputs[0].clone());\n    }\n    let mut field_0 = fields[0].clone();\n    let name = field_0.name().clone();\n    field_0.rename(fields[fields.len() - 1].name().clone());\n    let mut fields = fields[1..]\n        .iter()\n        .zip(fields[..fields.len() - 1].iter())\n        .map(|(s, name)| {\n            let mut s = s.clone();\n            s.rename(name.name().clone());\n            s\n        })\n        .collect::&lt;Vec&lt;_&gt;&gt;();\n    fields.push(field_0);\n    StructChunked::from_series(name, struct_.len(), fields.iter()).map(|ca| ca.into_series())\n}\n</code></pre> <p>Let's try this out. Put the following in <code>run.py</code>:</p> <pre><code>import polars as pl\nimport minimal_plugin as mp\n\ndf = pl.DataFrame(\n    {\n        \"a\": [1, 3, 8],\n        \"b\": [2.0, 3.1, 2.5],\n        \"c\": [\"3\", \"7\", \"3\"],\n    }\n).select(abc=pl.struct(\"a\", \"b\", \"c\"))\nprint(df.with_columns(abc_shifted=mp.shift_struct(\"abc\")))\n</code></pre> <p>Compile with <code>maturin develop</code> (or <code>maturin develop --release</code> if you're benchmarking), and if you run <code>python run.py</code> you'll see:</p> <pre><code>shape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 abc         \u2506 abc_shifted \u2502\n\u2502 ---         \u2506 ---         \u2502\n\u2502 struct[3]   \u2506 struct[3]   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 {1,2.0,\"3\"} \u2506 {2.0,\"3\",1} \u2502\n\u2502 {3,3.1,\"7\"} \u2506 {3.1,\"7\",3} \u2502\n\u2502 {8,2.5,\"3\"} \u2506 {2.5,\"3\",8} \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>The values look right - but is the schema? Let's take a look</p> <pre><code>import pprint\npprint.pprint(df.with_columns(abc_shifted=mp.shift_struct(\"abc\")).schema)\n</code></pre> <pre><code>OrderedDict([('abc', Struct({'a': Int64, 'b': Float64, 'c': String})),\n             ('abc_shifted', Struct({'a': Float64, 'b': String, 'c': Int64}))])\n</code></pre> <p>Looks correct!</p>"},{"location":"sum/","title":"3. How to do SUMthing","text":"<p>So far, the expressions we wrote only operated on a single expression.</p> <p>What if we'd like to do something fancier, involving more than one expression? Let's try to write an expression which lets us do</p> <pre><code>df.with_columns(mp.sum_i64('a', 'b'))\n</code></pre>"},{"location":"sum/#take-a-ride-on-the-python-side","title":"Take a ride on the Python side","text":"<p>First, we need to be able to pass multiple inputs to our Rust function. We'll do that by using the <code>args</code> argument when we register our expression. Add the following to <code>minimal_plugins/__init__.py</code>:</p> <pre><code>def sum_i64(expr: IntoExprColumn, other: IntoExprColumn) -&gt; pl.Expr:\n    return register_plugin_function(\n        args=[expr, other],\n        plugin_path=LIB,\n        function_name=\"sum_i64\",\n        is_elementwise=True,\n    )\n</code></pre>"},{"location":"sum/#ive-got-1100011-problems-but-binary-aint-one","title":"I\u2019ve got 1100011 problems but binary ain't one","text":"<p>Time to write a binary function, in the sense that it takes two columns as input and produces a third. Polars gives us a handy <code>broadcast_binary_elementwise</code> function for computing binary elementwise operations!</p> <p>Add the following to <code>src/expressions.rs</code>:</p> <p><pre><code>#[polars_expr(output_type=Int64)]\nfn sum_i64(inputs: &amp;[Series]) -&gt; PolarsResult&lt;Series&gt; {\n    let left: &amp;Int64Chunked = inputs[0].i64()?;\n    let right: &amp;Int64Chunked = inputs[1].i64()?;\n    // Note: there's a faster way of summing two columns, see\n    // section 7.\n    let out: Int64Chunked = broadcast_binary_elementwise(\n        left,\n        right,\n        |left: Option&lt;i64&gt;, right: Option&lt;i64&gt;| match (left, right) {\n            (Some(left), Some(right)) =&gt; Some(left + right),\n            _ =&gt; None,\n        },\n    );\n    Ok(out.into_series())\n}\n</code></pre> Note that you'll also need to add <pre><code>use polars::prelude::arity::broadcast_binary_elementwise;\n</code></pre> to the top of the <code>src/expressions.rs</code> file.</p> <p>Note</p> <p>There's a faster way of implementing this particular operation, which we'll cover later in the tutorial in Branch mispredictions.</p> <p>The idea is:</p> <ul> <li>for each row, if both <code>left</code> and <code>right</code> are valid (i.e. they are both   <code>Some</code>), then we sum them;</li> <li>if either of them is missing (<code>None</code>), then we return <code>None</code>.</li> </ul> <p>To try it out, remember to first compile with <code>maturin develop</code> (or <code>maturin develop --release</code> if you're benchmarking). Then if you make a <code>run.py</code> file with <pre><code>import polars as pl\nimport minimal_plugin as mp\n\ndf = pl.DataFrame({'a': [1, 5, 2], 'b': [3, None, -1]})\nprint(df.with_columns(a_plus_b=mp.sum_i64('a', 'b')))\n</code></pre> then <code>python run.py</code> should produce <pre><code>shape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b    \u2506 a_plus_b \u2502\n\u2502 --- \u2506 ---  \u2506 ---      \u2502\n\u2502 i64 \u2506 i64  \u2506 i64      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 3    \u2506 4        \u2502\n\u2502 5   \u2506 null \u2506 null     \u2502\n\u2502 2   \u2506 -1   \u2506 1        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"sum/#get-over-your-exercises","title":"Get over your exercises","text":"<p>It's widely acknowledged that the best way to learn is by doing.</p> <p>Can you make <code>sum_numeric</code> (a generic version of <code>sum_i64</code>)? Can you support the case when <code>left</code> and <code>right</code> are of different types, e.g. <code>i8</code> plus <code>i16</code>?</p>"},{"location":"vec_of_option/","title":"13. <code>Vec&lt;Option&lt;T&gt;&gt;</code> vs. <code>Vec&lt;T&gt;</code>","text":"<p>\"I got, I got, I got, I got options\" \u2013 Pitbull, before writing his first Polars plugin</p> <p>In the plugins we looked at so far, we typically created an iterator of options and let Polars collect it into a <code>ChunkedArray</code>. Sometimes, however, you need to store intermediate values in a <code>Vec</code>. You might be tempted to make it a <code>Vec&lt;Option&lt;T&gt;&gt;</code>, where missing values are <code>None</code> and present values are <code>Some</code>...</p> <p>\ud83d\uded1 BUT WAIT!</p> <p>Did you know that <code>Vec&lt;Option&lt;i32&gt;&gt;</code> occupies twice as much memory as <code>Vec&lt;i32&gt;</code>? Let's prove it:</p> <pre><code>use std::mem::size_of_val;\n\nfn main() {\n    let vector: Vec&lt;i32&gt; = vec![1, 2, 3];\n    println!(\"{}\", size_of_val(&amp;*vector));\n    // Output: 12\n\n    let vector: Vec&lt;Option&lt;i32&gt;&gt; = vec![Some(1), Some(2), Some(3)];\n    println!(\"{}\", size_of_val(&amp;*vector));\n    // Output: 24\n}\n</code></pre> <p>So...how can we create an output which includes missing values, without allocating twice as much memory as is necessary?</p>"},{"location":"vec_of_option/#validity-mask","title":"Validity mask","text":"<p>Instead of creating a vector of options, we can create a vector of primitive values with zeroes in place of the missing values, and use a validity mask to indicate which values are missing. One example of this can be seen in Polars' <code>interpolate_impl</code>, which does the heavy lifting for the <code>Series.interpolate</code>:</p> <pre><code>fn interpolate_impl&lt;T, I&gt;(chunked_arr: &amp;ChunkedArray&lt;T&gt;, interpolation_branch: I) -&gt; ChunkedArray&lt;T&gt;\nwhere\n    T: PolarsNumericType,\n    I: Fn(T::Native, T::Native, IdxSize, T::Native, &amp;mut Vec&lt;T::Native&gt;),\n{\n    // This implementation differs from pandas as that boundary None's are not removed.\n    // This prevents a lot of errors due to expressions leading to different lengths.\n    if !chunked_arr.has_nulls() || chunked_arr.null_count() == chunked_arr.len() {\n        return chunked_arr.clone();\n    }\n\n    // We first find the first and last so that we can set the null buffer.\n    let first = chunked_arr.first_non_null().unwrap();\n    let last = chunked_arr.last_non_null().unwrap() + 1;\n\n    // Fill out with `first` nulls.\n    let mut out = Vec::with_capacity(chunked_arr.len());\n    let mut iter = chunked_arr.iter().skip(first);\n    for _ in 0..first {\n        out.push(Zero::zero());\n    }\n\n    // The next element of `iter` is definitely `Some(Some(v))`, because we skipped the first\n    // elements `first` and if all values were missing we'd have done an early return.\n    let mut low = iter.next().unwrap().unwrap();\n    out.push(low);\n    while let Some(next) = iter.next() {\n        if let Some(v) = next {\n            out.push(v);\n            low = v;\n        } else {\n            let mut steps = 1 as IdxSize;\n            for next in iter.by_ref() {\n                steps += 1;\n                if let Some(high) = next {\n                    let steps_n: T::Native = NumCast::from(steps).unwrap();\n                    interpolation_branch(low, high, steps, steps_n, &amp;mut out);\n                    out.push(high);\n                    low = high;\n                    break;\n                }\n            }\n        }\n    }\n    if first != 0 || last != chunked_arr.len() {\n        let mut validity = MutableBitmap::with_capacity(chunked_arr.len());\n        validity.extend_constant(chunked_arr.len(), true);\n\n        for i in 0..first {\n            validity.set(i, false);\n        }\n\n        for i in last..chunked_arr.len() {\n            validity.set(i, false);\n            out.push(Zero::zero())\n        }\n\n        let array = PrimitiveArray::new(\n            T::get_dtype().to_arrow(CompatLevel::newest()),\n            out.into(),\n            Some(validity.into()),\n        );\n        ChunkedArray::with_chunk(PlSmallStr::EMPTY, array)\n    } else {\n        ChunkedArray::from_vec(chunked_arr.name(), out)\n    }\n}\n</code></pre> <p>That's a lot to digest at once, so let's take small steps and focus on the core logic. At the start, we store the indexes of the first and last non-null values:</p> <pre><code>let first = chunked_arr.first_non_null().unwrap();\nlet last = chunked_arr.last_non_null().unwrap() + 1;\n</code></pre> <p>We then create a vector <code>out</code> to store the result values in, and in places where we'd like the output to be missing, we push zeroes (we'll see below how we tell Polars that these are to be considered missing, rather than as ordinary zeroes):</p> <pre><code>let mut out = Vec::with_capacity(chunked_arr.len());\nfor _ in 0..first {\n    out.push(Zero::zero());\n}\n</code></pre> <p>We then skip the first <code>first</code> elements and start interpolating (note how we write <code>out.push(low)</code>, not <code>out.push(Some(low))</code> - we gloss over the rest as it's not related to the main focus of this chapter):</p> <pre><code>let mut iter = chunked_arr.iter().skip(first);\nlet mut low = iter.next().unwrap().unwrap();\nout.push(low);\nwhile let Some(next) = iter.next() {\n    // Interpolation logic\n}\n</code></pre> <p>Now, after most of the work is done and we've filled up most of <code>out</code>, we create a validity mask and set it to <code>false</code> for elements which we'd like to declare as missing:</p> <pre><code>if first != 0 || last != chunked_arr.len() {\n    // A validity mask is created for the vector, initially all set to true\n    let mut validity = MutableBitmap::with_capacity(chunked_arr.len());\n    validity.extend_constant(chunked_arr.len(), true);\n\n    for i in 0..first {\n        // The indexes corresponding to the zeroes before the first valid value\n        // are set to false (invalid)\n        validity.set(i, false);\n    }\n\n    for i in last..chunked_arr.len() {\n        // The indexes corresponding to the values after the last valid value\n        // are set to false (invalid)\n        validity.set(i, false);\n\n        out.push(Zero::zero())  // Push zeroes after the last valid value, as\n                                // many as there are nulls at the end, just like\n                                // it was done before the first valid value.\n    }\n\n    let array = PrimitiveArray::new(\n        T::get_dtype().to_arrow(CompatLevel::newest()),\n        out.into(),\n        Some(validity.into()),\n    );\n    ChunkedArray::with_chunk(PlSmallStr::EMPTY, array)\n} else {\n    ChunkedArray::from_vec(chunked_arr.name(), out)\n}\n</code></pre> <p>The <code>MutableBitmap</code> only requires one byte per 8 elements, so the total space used is much less than it would've been if we'd created <code>out</code> as a vector of options! Further, note how the validity mask is only allocated when the output contains nulls - if there are no nulls, we can save even more memory by not having a validity mask at all!</p>"},{"location":"vec_of_option/#sentinel-values","title":"Sentinel values","text":"<p>Let's look at another example of where it's possible to avoid allocating a vector of options. This example comes from the Polars-XDT plugin. There's one function there which creates a temporary <code>idx</code> vector in which, for each element, we store the index of the previous element larger than it. If an element has no previous larger element, then rather than storing <code>None</code> (thus forcing all non-missing elements to be <code>Some</code>), we can just store <code>-1</code>.</p> <p>Take a look at this diff from a PR which does exactly that, in which most changes are along the lines of:</p> <pre><code>-            if i &lt; Some(0) {\n-                idx.push(None);\n+            if i &lt; 0 {\n+                idx.push(-1);\n</code></pre> <p>There's no functional behaviour change, but we already know the memory benefits!</p>"},{"location":"vec_of_option/#conclusion","title":"Conclusion","text":"<p>In general, if you can avoid allocating <code>Vec&lt;Option&lt;T&gt;&gt;</code> instead of <code>Vec&lt;T&gt;</code>, do it!!</p> <p>Note</p> <p>This advice only applies if you're creating a vector to store results in. If you're collecting an iterator of options into a chunked array, then Polars already optimises this for you.</p>"},{"location":"where_to_go/","title":"Where to go from here?","text":"<p>What now?</p> <p>If this material was a bit overwhelming for you, I'd suggest taking a step back and reading The Rust Programming Language. Or at least, the first 10 chapters.</p> <p>Next, you may be interested in looking at existing plugins for inspiration. There's a nice list of them in the official user guide: https://docs.pola.rs/user-guide/plugins/your-first-polars-plugin/#community-plugins.</p> <p>Finally, you should definitely join the Discord Server, where there's a channel dedicated to plugins: https://discord.gg/4UfP5cfBE7.</p>"}]}